<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Simbiosis Humano-IA - Exposici√≥n Acad√©mica</title>
    <link rel="stylesheet" href="exposicion.css">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
</head>a
<body>
    <div class="container">
        <header class="main-header">
            <h1>Simbiosis humano-IA</h1>
            <h2>Explorando la delegaci√≥n y la recalibraci√≥n constante de la agencia</h2>
            <h3>A trav√©s de IA generativa</h3>
        </header>

        <div class="content-wrapper">
            <!-- Resumen Ejecutivo de la Investigaci√≥n -->
            <div class="executive-summary">
                <div class="summary-container">
                    <h2>Resumen Ejecutivo de la Investigaci√≥n</h2>
                    
                    <div class="summary-section">
                        <h3>Problema (1)</h3>
                        <p>En el municipio sueco, las tareas administrativas son muy repetitivas y consumen tiempo (ej. transcripci√≥n de actas, redacci√≥n de informes, procesamiento de solicitudes). Surge el problema de c√≥mo integrar la IA generativa (Copilot) para aumentar la eficiencia sin perder confianza, transparencia ni equidad.</p>
                    </div>
                    
                    <div class="summary-section">
                        <h3>Objetivos (2)</h3>
                        <p><strong>Objetivo General:</strong> Analizar el impacto de la implementaci√≥n de IA generativa (Copilot) en los procesos administrativos de un municipio sueco, considerando sus efectos en la eficiencia, la innovaci√≥n, la confianza y la redefinici√≥n de roles en el sector p√∫blico.</p>
                        
                        <p><strong>Objetivos Espec√≠ficos:</strong></p>
                        <ul>
                            <li><strong>Eficiencia:</strong> Evaluar el grado de eficiencia alcanzado mediante la delegaci√≥n de tareas administrativas a Copilot</li>
                            <li><strong>Innovaci√≥n:</strong> Examinar c√≥mo Copilot promueve o limita la innovaci√≥n en los procesos de trabajo</li>
                            <li><strong>Confianza:</strong> Analizar las percepciones de los empleados respecto a la confianza en los resultados generados por Copilot</li>
                            <li><strong>Roles:</strong> Identificar los cambios en los roles y din√°micas laborales derivados de la introducci√≥n de Copilot</li>
                            <li><strong>Gobernanza:</strong> Explorar los desaf√≠os √©ticos, organizacionales y de gobernanza que emergen con la implementaci√≥n de IA generativa</li>
                        </ul>
                    </div>
                    
                    <div class="summary-section">
                        <h3>Marco Te√≥rico (3 y 4)</h3>
                        <p>Desde los padres de la IA, <strong>Turing</strong> preguntaba si una m√°quina puede "pensar"; esto se refleja hoy en si Copilot realmente ayuda a tomar decisiones o solo imita un asistente.</p>
                        <p><strong>John McCarthy</strong> defini√≥ la IA como m√°quinas inteligentes, y en tu caso Copilot act√∫a como tal al redactar informes o responder consultas.</p>
                        <p>Con <strong>Minsky</strong>, la idea de redes neuronales se plasma en la IA generativa de Copilot que aprende patrones de texto.</p>
                        <p><strong>Simon & Newell</strong>, con la resoluci√≥n l√≥gica, se relacionan con Copilot procesando datos y generando salidas organizadas.</p>
                        <p><strong>Wiener</strong>, con la cibern√©tica, conecta con la retroalimentaci√≥n constante entre usuarios y Copilot, que se recalibra seg√∫n la interacci√≥n.</p>
                        <p>Autores contempor√°neos como <strong>Kaplan, Haenlein, Davenport y Mikalef</strong> extienden estas ideas al terreno actual: confianza, √©tica, gobernanza y estrategia digital en instituciones p√∫blicas.</p>
                        
                        <h4>Fundamentos de la Teor√≠a de la Informaci√≥n</h4>
                        <p>La <strong>Teor√≠a de la Informaci√≥n</strong>, desarrollada por <strong>Claude Shannon</strong>, proporciona el marco matem√°tico fundamental para entender c√≥mo se procesa, transmite y almacena la informaci√≥n en sistemas complejos. En el contexto de la IA generativa como Copilot, esta teor√≠a explica:</p>
                        <ul>
                            <li><strong>Entrop√≠a de la informaci√≥n:</strong> Mide la incertidumbre y el contenido informativo de los mensajes que procesa la IA</li>
                            <li><strong>Codificaci√≥n eficiente:</strong> C√≥mo la IA optimiza la representaci√≥n de datos para maximizar la informaci√≥n √∫til</li>
                            <li><strong>Canales de comunicaci√≥n:</strong> Los procesos de interacci√≥n humano-IA como sistemas de transmisi√≥n de informaci√≥n</li>
                            <li><strong>Redundancia y ruido:</strong> C√≥mo la IA filtra informaci√≥n irrelevante y mantiene la coherencia en sus respuestas</li>
                        </ul>
                        <p>Esta perspectiva te√≥rica permite entender la colaboraci√≥n humano-IA como un <strong>sistema de comunicaci√≥n bidireccional</strong> donde la informaci√≥n fluye, se procesa y se retroalimenta continuamente, optimizando tanto la eficiencia algor√≠tmica como la comprensi√≥n humana.</p>
                    </div>
                    
                    <div class="summary-section">
                        <h3>Metodolog√≠a de investigaci√≥n (5)</h3>
                        <p>Decidiste usar un estudio de caso (el municipio sueco) y entrevistas semiestructuradas con empleados que usan Copilot. Esto te permite recoger sus percepciones reales: algunos lo ven como un <strong>"secretario eficiente"</strong>, otros como un <strong>"coautor"</strong>, y otros sienten temor de perder autonom√≠a.</p>
                    </div>
                    
                    <div class="summary-section">
                        <h3>Metodolog√≠a de implementaci√≥n ‚Äì IA (6)</h3>
                        <p>Aqu√≠ describes c√≥mo se integra Copilot en la pr√°ctica:</p>
                        <ul>
                            <li><strong>Licencias limitadas</strong> ‚Üí genera desigualdad de acceso.</li>
                            <li><strong>Automatiza lo rutinario</strong> (transcripci√≥n, s√≠ntesis) ‚Üí libera tiempo humano.</li>
                            <li><strong>Requiere supervisi√≥n humana</strong> para temas sensibles (privacidad, decisiones cr√≠ticas).</li>
                        </ul>
                        <p>La implementaci√≥n incluye capacitaciones y pruebas piloto, lo cual muestra que la adopci√≥n no es solo t√©cnica, sino tambi√©n cultural.</p>
                    </div>
                    
                    <div class="summary-section">
                        <h3>Resultados (7)</h3>
                        <p><strong>Resumen de Hallazgos por Objetivo:</strong></p>
                        <ul>
                            <li><strong>Eficiencia:</strong> Copilot permiti√≥ ahorrar tiempo en tareas repetitivas, aunque la revisi√≥n y correcci√≥n de salidas demand√≥ tiempo adicional, matizando la percepci√≥n de eficiencia total.</li>
                            <li><strong>Innovaci√≥n:</strong> La herramienta facilit√≥ nuevas formas de trabajo y generaci√≥n r√°pida de borradores, pero algunos resultados fueron percibidos como "est√°ndar" o "aburridos", limitando la creatividad.</li>
                            <li><strong>Confianza:</strong> Se evidenci√≥ confianza moderada: √∫til para tareas mec√°nicas, pero con dudas en contextos sensibles, manteniendo la necesidad de supervisi√≥n humana.</li>
                            <li><strong>Roles:</strong> Se observ√≥ reconfiguraci√≥n de roles: Copilot como "asistente" o "coautor", pero con preocupaciones sobre p√©rdida de autonom√≠a y desigualdad en acceso a licencias.</li>
                            <li><strong>Gobernanza:</strong> Emergieron desaf√≠os clave: desigualdad de acceso, privacidad de datos, gobernanza organizacional y dependencia tecnol√≥gica.</li>
                        </ul>
                        <p>Los resultados demuestran que la IA es √∫til pero requiere gobernanza √©tica y supervisi√≥n humana para una implementaci√≥n sostenible en el sector p√∫blico.</p>
                    </div>
                </div>
            </div>
            
            <div class="column">
                <section class="section">
                    <h2>Resumen</h2>
                    <p>Este estudio examina la implementaci√≥n de <strong>inteligencia artificial generativa</strong> en el sector p√∫blico, aplicando un enfoque de <strong>pensamiento sist√©mico</strong> para analizar los procesos de delegaci√≥n din√°mica y recalibraci√≥n de agencia entre humanos y m√°quinas. La investigaci√≥n se fundamenta en el <strong>modelado</strong> de sistemas h√≠bridos y la <strong>simulaci√≥n</strong> de escenarios de colaboraci√≥n humano-IA.</p>
                    
                    <p>Mediante un <strong>estudio de caso cualitativo</strong> en un municipio sueco, se analiza la colaboraci√≥n simbi√≥tica que emerge cuando los sistemas de IA generativa se integran en entornos organizacionales complejos. El enfoque metodol√≥gico combina <strong>an√°lisis cualitativo</strong> con t√©cnicas de <strong>optimizaci√≥n</strong> de procesos, utilizando la metodolog√≠a Gioia para la codificaci√≥n y an√°lisis de datos.</p>
                    
                    <p>El estudio propone un <strong>marco conceptual</strong> basado en <strong>delegaci√≥n bidireccional</strong> y <strong>recalibraci√≥n de agencia</strong>, posicionando la IA generativa como una <strong>herramienta de apoyo a la toma de decisiones</strong> que complementa las capacidades humanas. Los resultados evidencian la evoluci√≥n hacia sistemas h√≠bridos que optimizan tanto la eficiencia algor√≠tmica como la supervisi√≥n humana, estableciendo un modelo de <strong>sistemas blandos</strong> adaptativos para la gobernanza p√∫blica.</p>
                </section>

                <section class="section">
                    <h2>Planteamiento del Problema y Objetivos</h2>
                    <h3>Problema Central</h3>
                    <p>La distribuci√≥n de agencia entre humanos y m√°quinas presenta tensiones fundamentales entre la eficiencia algor√≠tmica y la necesidad de supervisi√≥n humana. Esta tensi√≥n se intensifica en el sector p√∫blico, donde las decisiones tienen implicaciones directas en la vida ciudadana.</p>
                    
                    <h3>Justificaci√≥n Contextual</h3>
                    <p>La modernizaci√≥n del sector p√∫blico mediante IA genera dilemas √©ticos complejos que requieren marcos conceptuales robustos para guiar la implementaci√≥n responsable de estas tecnolog√≠as.</p>
                    
                    <h3>Objetivo General</h3>
                    <p>Analizar el impacto de la implementaci√≥n de la inteligencia artificial generativa (Copilot) en los procesos administrativos de un municipio sueco, considerando sus efectos en la eficiencia, la innovaci√≥n, la confianza y la redefinici√≥n de roles en el sector p√∫blico.</p>
                    
                    <h3>üéØ Objetivos Espec√≠ficos</h3>
                    <ol>
                        <li><strong>Evaluar el grado de eficiencia</strong> alcanzado mediante la delegaci√≥n de tareas administrativas a Copilot, en comparaci√≥n con los m√©todos tradicionales.</li>
                        <li><strong>Examinar de qu√© manera Copilot promueve o limita la innovaci√≥n</strong> en los procesos de trabajo del municipio.</li>
                        <li><strong>Analizar las percepciones de los empleados</strong> respecto a la confianza en los resultados generados por Copilot y su influencia en la toma de decisiones.</li>
                        <li><strong>Identificar los cambios en los roles y din√°micas laborales</strong> derivados de la introducci√≥n de Copilot en la gesti√≥n p√∫blica.</li>
                        <li><strong>Explorar los desaf√≠os √©ticos, organizacionales y de gobernanza</strong> que emergen con la implementaci√≥n de inteligencia artificial generativa en el sector p√∫blico.</li>
                    </ol>
                </section>

                <section class="section">
                    <h2>Marco Te√≥rico</h2>
                    <h3>Fundamentos de la Inteligencia Artificial</h3>
                    <p>La Inteligencia Artificial (IA) no naci√≥ de un solo cient√≠fico, sino de un grupo de pensadores y disciplinas que se unieron en los a√±os 40‚Äì50 y se consolidaron como campo formal en 1956. Desde entonces, la IA se ha definido como una disciplina de la inform√°tica encargada de desarrollar sistemas y programas capaces de realizar tareas que normalmente requieren inteligencia humana, como el razonamiento, la toma de decisiones, el aprendizaje y la adaptaci√≥n.</p>
                    
                    <p>En el presente estudio, se aborda la IA desde una perspectiva cognitiva y simbi√≥tica, enfocada en su capacidad para colaborar con humanos en entornos complejos como el sector p√∫blico.</p>
                    
                    <h3>Herbert Simon y la Racionalidad Limitada</h3>
                    <p>Esta visi√≥n se articula con los aportes de <strong>Herbert Simon</strong>, citado en el documento base de esta investigaci√≥n, quien fue pionero en el estudio de la toma de decisiones administrativas y en el desarrollo de modelos computacionales que simulan procesos cognitivos humanos. Su teor√≠a de la <strong>racionalidad limitada</strong> no solo transform√≥ la gesti√≥n p√∫blica, sino que tambi√©n sent√≥ las bases para el dise√±o de sistemas inteligentes capaces de colaborar con humanos en entornos inciertos.</p>
                    
                    <p>En este marco, la IA no se concibe como sustituto del juicio humano, sino como <strong>amplificador cognitivo</strong>, capaz de extender la capacidad de an√°lisis, s√≠ntesis y decisi√≥n en contextos organizacionales.</p>
                    
                    <h3>Modelos de Delegaci√≥n en Sistemas Humano-IA</h3>
                    <p>Para comprender la din√°mica de colaboraci√≥n entre humanos y sistemas de inteligencia artificial, es fundamental analizar los modelos de delegaci√≥n que estructuran dicha interacci√≥n. Diversos estudios han identificado tres tipos principales de delegaci√≥n: de humano a IA, de IA a humano, y bidireccional. Estos modelos permiten mapear c√≥mo se distribuyen las responsabilidades en sistemas inteligentes y c√≥mo se recalibra la agencia en funci√≥n del contexto, la competencia y el aprendizaje mutuo.</p>
                    
                    <div class="image-container">
                        <h4>Tabla 2. Tipos de delegaci√≥n en sistemas humano-IA: definici√≥n y referencias clave</h4>
                        <img src="qwe123.png" alt="Tabla de tipos de delegaci√≥n en sistemas humano-IA" class="methodology-image">
                    </div>
                    
                    <h3>An√°lisis de los Modelos de Delegaci√≥n</h3>
                    <p>La tabla sintetiza los tres modelos de delegaci√≥n m√°s relevantes en el campo de la interacci√≥n humano-IA.</p>
                    
                    <ul>
                        <li>En la <strong>delegaci√≥n Humano-IA</strong>, el humano asigna tareas al sistema, manteniendo supervisi√≥n parcial.</li>
                        <li>En la <strong>delegaci√≥n IA-Humano</strong>, el sistema transfiere decisiones al humano, evaluando su competencia.</li>
                        <li>En la <strong>delegaci√≥n bidireccional</strong>, ambos actores colaboran activamente, ajustando sus roles seg√∫n el flujo de trabajo.</li>
                    </ul>
                    
                    <p>Estos modelos, respaldados por autores como Shrestha, F√ºgener, Carroll y Lebovitz, constituyen la base conceptual para entender la <strong>simbiosis humano-IA</strong>. En particular, la delegaci√≥n bidireccional representa el ideal de colaboraci√≥n adaptativa, donde la agencia se distribuye din√°micamente y se retroalimenta en tiempo real. Este marco te√≥rico se conecta directamente con los principios de la <strong>cibern√©tica organizacional</strong>, al considerar la interacci√≥n como un sistema auto-regulado, sensible al entorno y capaz de evolucionar.</p>
                    
                    <h3>Recalibraci√≥n de Agencia</h3>
                    <p>Basada en la teor√≠a de la racionalidad limitada, la recalibraci√≥n permite ajustes din√°micos en la distribuci√≥n de responsabilidades seg√∫n el contexto y el desempe√±o del sistema.</p>
                    
                    <h3>Simbiosis Humano-IA</h3>
                    <p>Inspirada en la cibern√©tica organizacional, esta relaci√≥n mutuamente beneficiosa optimiza las capacidades tanto humanas como artificiales, creando sinergias que superan las limitaciones individuales.</p>
                    
                    <h3>Conceptos</h3>
                    <p><strong>Holmstr√∂m y Carroll (2024)</strong> ilustran a√∫n m√°s este punto de vista al enfatizar la perspectiva de una relaci√≥n mutuamente interdependiente en lugar de una de exclusi√≥n, y al enfatizar los beneficios sin√©rgicos. La perspectiva tradicional sugiere que la IA es superior a los humanos en el procesamiento del lenguaje y el reconocimiento de patrones <strong>(Shrestha et al., 2019)</strong>.</p>
                    
                    <p>Por lo tanto, en el √°mbito m√©dico, por ejemplo, se utilizaron agentes de IA para filtrar alternativas y reducirlas, mientras que el agente humano, es decir, el profesional m√©dico, evaluaba esas opciones y tomaba la decisi√≥n final como una forma de aumento participativo <strong>(Lebovitz et al., 2022)</strong>. En consecuencia, el desarrollo de la IA puede considerarse una din√°mica dial√©ctica y mutuamente dependiente entre los humanos y la IA <strong>(Van den Broek et al., 2021; Shrestha et al., 2019)</strong>.</p>
                    
                    <p>Si bien se alaba la capacidad de la IA para analizar grandes vol√∫menes de datos y reconocer patrones, la contextualizaci√≥n, el razonamiento √©tico y la reflexividad cr√≠tica que proporciona sentido solo se manifiestan en humanos <strong>(Sundberg y Holmstr√∂m, 2024)</strong>. Este tipo de relaci√≥n simbi√≥tica es una v√≠a que impulsar√≠a a√∫n m√°s el proceso de aprendizaje, perfeccionando as√≠ las habilidades algor√≠tmicas junto con la inteligencia humana <strong>(Van den Broek et al., 2021)</strong>.</p>
                    
                    <p>Por esto <strong>Kaplan & Haenlein</strong> definen la IA como la capacidad de interpretar datos y adaptarse a objetivos espec√≠ficos, retomando la discusi√≥n iniciada por <strong>Alan Turing</strong>, quien plante√≥ la pregunta sobre qu√© significa realmente considerar a una m√°quina inteligente mediante su Test de Turing.</p>
                    
                    <p><strong>Brynjolfsson & McAfee</strong> destacan el impacto econ√≥mico y organizacional de la IA, ampliando la visi√≥n de <strong>John McCarthy</strong>, quien acu√±√≥ el t√©rmino Inteligencia Artificial y la present√≥ como la ciencia de construir m√°quinas inteligentes.</p>
                    
                    <p>Las ideas de <strong>Marvin Minsky</strong> sobre la mente como proceso computable y sus avances en redes neuronales encuentran eco en los trabajos de <strong>Brynjolfsson, McAfee y Davenport</strong>, quienes analizan c√≥mo el aprendizaje autom√°tico transforma la productividad y la toma de decisiones.</p>
                    
                    <p>Los aportes de <strong>Herbert Simon y Allen Newell</strong> en la resoluci√≥n l√≥gica de problemas se reflejan en las reflexiones de <strong>Davenport y Mittelstadt</strong>, que discuten los l√≠mites y riesgos de delegar decisiones a los algoritmos, subrayando la importancia de la transparencia y la rendici√≥n de cuentas.</p>
                    
                    <p>La visi√≥n de <strong>Norbert Wiener</strong> sobre la cibern√©tica y los sistemas de retroalimentaci√≥n humano-m√°quina se prolonga en los estudios de <strong>Kaplan, Haenlein y Mikalef</strong>, quienes analizan la necesidad de confianza, gobernanza y ajuste continuo en los ecosistemas h√≠bridos de colaboraci√≥n humano-IA.</p>
                </section>
            </div>

            <div class="column">
                <section class="section">
                    <h2>Gobernanza √âtica</h2>
                    <p>Los principios fundamentales incluyen la <strong>transparencia</strong> en los procesos algor√≠tmicos, la <strong>responsabilidad compartida</strong> entre humanos y sistemas, y la <strong>equidad organizacional</strong> en la distribuci√≥n de beneficios y riesgos.</p>
                    
                    <h3>Conexiones Conceptuales</h3>
                    <ul>
                        <li>Automatizaci√≥n h√≠brida: combinaci√≥n de control humano y autom√°tico</li>
                        <li>Ingenier√≠a de prompts: optimizaci√≥n de interacciones humano-IA</li>
                        <li>√âtica algor√≠tmica: marcos para decisiones justas y transparentes</li>
                    </ul>
                </section>

                <section class="section">
                    <h2>Metodolog√≠a</h2>
                    
                    <h3>1. Metodolog√≠a de Investigaci√≥n</h3>
                    
                    <h4>Enfoques</h4>
                    <p>La presente investigaci√≥n adopta un <strong>enfoque cualitativo</strong> para analizar la interacci√≥n entre humanos y sistemas de inteligencia artificial generativa en el sector p√∫blico. Se busca comprender c√≥mo se distribuyen las responsabilidades entre ambos actores y c√≥mo se ajusta la agencia humana en funci√≥n del desempe√±o algor√≠tmico.</p>
                    
                    <p>Se utiliz√≥ un <strong>estudio de caso</strong> en un municipio sueco que implement√≥ Microsoft Copilot como herramienta de IA generativa en tareas administrativas. La recolecci√≥n de datos se realiz√≥ mediante <strong>entrevistas semiestructuradas</strong> a empleados p√∫blicos, enfocadas en sus experiencias de delegaci√≥n, confianza y colaboraci√≥n con la IA.</p>
                    
                    <p>Para el an√°lisis, se aplic√≥ la <strong>metodolog√≠a Gioia</strong>, que permite construir teor√≠a a partir de datos emp√≠ricos mediante codificaci√≥n abierta, axial y agregada. Este enfoque facilit√≥ la identificaci√≥n de conceptos de primer orden (acciones observadas), categor√≠as de segundo orden (interpretaciones organizacionales), y dimensiones agregadas (constructos te√≥ricos).</p>
                    
                    <p>El comportamiento observado en la interacci√≥n humano-IA refleja principios de la <strong>cibern√©tica organizacional</strong>, especialmente en lo que respecta a la <strong>retroalimentaci√≥n continua</strong> y el <strong>control adaptativo</strong>. Los participantes ajustaban sus decisiones en funci√≥n de las respuestas de la IA, y la IA, a su vez, modificaba sus recomendaciones seg√∫n el contexto y el historial de uso. Este ciclo de ajuste din√°mico constituye un sistema auto-regulado, alineado con los postulados de <strong>Norbert Wiener</strong> sobre control y comunicaci√≥n en sistemas inteligentes.</p>
                    
                    <h3>2. Metodolog√≠a de Implementaci√≥n ‚Äì IA (Caracter√≠sticas)</h3>
                    
                    <h4>Tipo de IA utilizada</h4>
                    <p><strong>IA generativa</strong> (Microsoft Copilot) basada en modelos de lenguaje de gran escala (LLM), con capacidad de procesar lenguaje natural, redactar documentos y asistir en tareas administrativas.</p>
                    
                    <h4>Caracter√≠sticas t√©cnicas</h4>
                    <ul>
                        <li><strong>Automatizaci√≥n:</strong> Delegaci√≥n de tareas repetitivas y de bajo valor cognitivo</li>
                        <li><strong>Aumentaci√≥n:</strong> Asistencia en toma de decisiones y apoyo en creatividad (redacci√≥n de informes, s√≠ntesis de datos)</li>
                        <li><strong>Retroalimentaci√≥n continua:</strong> La herramienta aprende y se ajusta a trav√©s del uso</li>
                        <li><strong>Transparencia limitada:</strong> Dependencia de la explicabilidad y confianza en los resultados</li>
                    </ul>
                    
                    <h4>Proceso de integraci√≥n</h4>
                    <ul>
                        <li><strong>Fase piloto:</strong> Uso experimental en administraci√≥n municipal</li>
                        <li><strong>Asignaci√≥n de licencias:</strong> Distribuci√≥n restringida, generando din√°micas de acceso desigual</li>
                        <li><strong>Pruebas de usabilidad:</strong> Talleres, sesiones de aprendizaje y experimentaci√≥n</li>
                        <li><strong>Evaluaci√≥n de desempe√±o:</strong> Medici√≥n de eficiencia, ahorro de tiempo y calidad de tareas</li>
                    </ul>
                    
                    <h4>Consideraciones √©ticas y factores de √©xito</h4>
                    <ul>
                        <li><strong>Privacidad de datos:</strong> Anonimizaci√≥n de informaci√≥n sensible</li>
                        <li><strong>Supervisi√≥n humana:</strong> Usuario mantiene responsabilidad en decisiones cr√≠ticas</li>
                        <li><strong>Capacitaci√≥n:</strong> Alfabetizaci√≥n digital y prompt engineering</li>
                        <li><strong>Cultura organizacional:</strong> Apertura al cambio tecnol√≥gico</li>
                    </ul>
                    
                    <h3>An√°lisis Inductivo y Mapa Conceptual</h3>
                    <p>Como parte del an√°lisis cualitativo, se utiliz√≥ un enfoque inductivo para identificar patrones emergentes en la interacci√≥n humano-IA dentro el sector p√∫blico. Para ello, se construy√≥ un mapa conceptual que sintetiza las dimensiones clave observadas durante el estudio de caso. Este diagrama representa las categor√≠as tem√°ticas que surgieron del proceso de codificaci√≥n, alineadas con la metodolog√≠a Gioia.</p>
                    
                    <div class="image-container">
                        <h4>Dimensiones emergentes en la interacci√≥n humano-IA</h4>
                        <img src="asdf.png" alt="Mapa conceptual de dimensiones emergentes en la interacci√≥n humano-IA" class="methodology-image">
                    </div>
                    
                    <h3>An√°lisis de Datos y Metodolog√≠a Gioia</h3>
                    <p>Siguiendo los pasos sistem√°tico-inductivos tradicionales de la metodolog√≠a Gioia, nuestro an√°lisis combina una profunda interacci√≥n con los informantes en un enfoque iterativo de construcci√≥n te√≥rica <strong>(Gioia et al., 2013)</strong>. Parte del supuesto de que los participantes son "agentes con conocimiento" capaces de expresar con elocuencia sus experiencias y la construcci√≥n de significado.</p>
                    
                    <p>Las entrevistas semiestructuradas se realizaron en un municipio sueco para comprender c√≥mo los empleados integran e interpretan Microsoft Copilot en sus operaciones diarias. Esta atenci√≥n a las palabras de los informantes mejor√≥ nuestra codificaci√≥n in vivo y nos permiti√≥ capturar las expresiones de los participantes sin imponer preconcepciones te√≥ricas prematuras <strong>(Gioia et al., 2013; Corley y Gioia, 2004)</strong>.</p>
                    
                    <h4>Ejemplo Pr√°ctico de Codificaci√≥n</h4>
                    <p>Un hallazgo revelador emergi√≥ durante la codificaci√≥n: los empleados se refer√≠an a Copilot de manera variable seg√∫n su funci√≥n percibida. En ocasiones lo consideraban una <strong>"secretaria de oficina m√°s eficiente"</strong> para tareas rutinarias, mientras que en otras lo describ√≠an como <strong>"profesor o coautor"</strong> para funciones creativas. Esta variabilidad en las etiquetas sugiere que Copilot opera bajo m√∫ltiples roles simult√°neos, desde resolver tareas pr√°cticas cotidianas hasta facilitar colaboraciones m√°s amplias.</p>
                    
                    <h3>Proceso de Codificaci√≥n Gioia</h3>
                    <p>Tras realizar la codificaci√≥n in vivo, desarrollamos conjuntos preliminares de c√≥digos de primer orden. Para mejorar la credibilidad y el rigor del an√°lisis, cada autor analiz√≥ de forma independiente la codificaci√≥n in vivo <strong>(Denzin, 1978; Patton, 1999)</strong>. Uno gener√≥ 105 c√≥digos a partir de 641 citas, mientras que el otro 176 c√≥digos a partir de 460. Estos conjuntos se triangularon mediante comparaciones iterativas.</p>
                    
                    <p>Los temas de segundo orden se presentan como ideas estrechamente situadas y conceptualmente relacionadas, representativas de ideas subyacentes m√°s abstractas. Se sigui√≥ la gu√≠a de <strong>Pratt (2009)</strong> sobre las "citas de poder", utilizadas para mostrar datos en lugar de simplemente describirlos, creando as√≠ una cadena de evidencia que destaca c√≥mo las voces de los informantes informan cr√≠ticamente nuestras perspectivas te√≥ricas.</p>
                    
                    <p>El proceso culmin√≥ en la derivaci√≥n de 15 conceptos de primer orden, sus correspondientes temas de segundo orden y cinco dimensiones agregadas, generando as√≠ un resultado preliminar del an√°lisis de Gioia que estructura el modelo conceptual propuesto.</p>
                    
                    <p>El diagrama refleja esta progresi√≥n inductiva, mostrando c√≥mo la adopci√≥n de IA generativa impacta m√∫ltiples niveles organizacionales: desde la automatizaci√≥n de tareas hasta la redefinici√≥n de roles humanos, pasando por la necesidad de estrategias sostenibles y protocolos √©ticos. Cada categor√≠a representa un nodo de an√°lisis que contribuye a entender la simbiosis humano-IA como un sistema adaptativo, distribuido y en constante recalibraci√≥n.</p>
                    
                    <h3>Dimensiones Emergentes</h3>
                    <ul>
                        <li>Transformaci√≥n laboral y nuevas competencias</li>
                        <li>Gobernanza √©tica en sistemas h√≠bridos</li>
                        <li>Ecosistemas h√≠bridos de colaboraci√≥n</li>
                        <li>Construcci√≥n de confianza humano-IA</li>
                        <li>Estrategias para implementaci√≥n sostenible</li>
                    </ul>
                </section>

                <section class="section">
                    <h2>üìä Resultados</h2>
                    
                    <h3>Objetivo 1: Evaluar el grado de eficiencia alcanzado mediante la delegaci√≥n de tareas administrativas a Copilot</h3>
                    <p>Los resultados muestran que Copilot permiti√≥ ahorrar tiempo en tareas repetitivas como la redacci√≥n de informes, la transcripci√≥n de actas y la s√≠ntesis de documentos extensos. Los empleados reportaron una reducci√≥n significativa de la carga administrativa, lo que les permiti√≥ destinar m√°s tiempo a actividades estrat√©gicas. Sin embargo, tambi√©n se√±alaron que en algunos casos la revisi√≥n y correcci√≥n de las salidas de Copilot demand√≥ tiempo adicional, lo que matiz√≥ la percepci√≥n de eficiencia total.</p>
                    
                    <h3>Objetivo 2: Examinar de qu√© manera Copilot promueve o limita la innovaci√≥n en los procesos de trabajo</h3>
                    <p>La herramienta fue percibida como un facilitador de nuevas formas de trabajo, ya que posibilit√≥ la generaci√≥n r√°pida de borradores y propuestas que antes demandaban mucho esfuerzo. Esto abri√≥ espacio para la creatividad en la edici√≥n y mejora de textos. No obstante, algunos entrevistados afirmaron que los resultados de Copilot eran <strong>"est√°ndar"</strong> o <strong>"aburridos"</strong>, lo que podr√≠a limitar la innovaci√≥n en contextos que demandan un estilo comunicativo m√°s humano o creativo.</p>
                    
                    <h3>Objetivo 3: Analizar las percepciones de los empleados respecto a la confianza en los resultados generados por Copilot</h3>
                    <p>Las entrevistas evidenciaron una confianza moderada en Copilot: los usuarios reconocieron su utilidad para tareas mec√°nicas, pero expresaron dudas sobre la precisi√≥n y fiabilidad de los textos en contextos m√°s sensibles, como comunicaciones oficiales o documentos jur√≠dicos. Esto refleja que los empleados a√∫n consideran indispensable la supervisi√≥n humana para validar la calidad de los resultados.</p>
                    
                    <h3>Objetivo 4: Identificar los cambios en los roles y din√°micas laborales derivados de la introducci√≥n de Copilot</h3>
                    <p>Se observ√≥ una reconfiguraci√≥n de los roles en el trabajo diario: Copilot fue asumido por algunos como un <strong>"asistente"</strong> que libera carga administrativa, mientras que otros lo percibieron como un <strong>"coautor"</strong> que colabora en la elaboraci√≥n de documentos. Sin embargo, tambi√©n emergi√≥ la preocupaci√≥n por la p√©rdida de autonom√≠a y competencias profesionales, especialmente entre quienes temen depender demasiado de la herramienta o quedar en desventaja si no se les asigna una licencia.</p>
                    
                    <h3>Objetivo 5: Explorar los desaf√≠os √©ticos, organizacionales y de gobernanza que emergen con la implementaci√≥n de IA generativa en el sector p√∫blico</h3>
                    <p>Los hallazgos indican que los principales desaf√≠os son:</p>
                    <ul>
                        <li><strong>Desigualdad en el acceso,</strong> debido a la distribuci√≥n limitada de licencias.</li>
                        <li><strong>Privacidad y manejo de datos,</strong> pues algunos empleados expresaron incertidumbre sobre la seguridad de la informaci√≥n procesada.</li>
                        <li><strong>Gobernanza organizacional,</strong> ya que la integraci√≥n de Copilot requiere lineamientos claros de uso y pol√≠ticas que garanticen transparencia y equidad.</li>
                        <li><strong>Dependencia tecnol√≥gica,</strong> que genera tensiones sobre hasta qu√© punto se debe confiar en un sistema que no siempre explica sus resultados.</li>
                    </ul>
                </section>
            </div>
        </div>

        <!-- Nueva Secci√≥n: Art√≠culo sobre Offline Reinforcement Learning -->
        <div class="content-wrapper">
            <!-- Columna Izquierda: Contenido Completo -->
            <div class="column">
                <section class="section">
                    <h2>Towards Optimizing Human-Centric Objectives in AI-Assisted Decision-Making With Offline Reinforcement Learning</h2>
                    
                    <h3>1. Resumen del art√≠culo</h3>
                    <p>El estudio propone el uso de <strong>aprendizaje por refuerzo offline (Offline RL)</strong> para mejorar la toma de decisiones asistida por IA, no solo en t√©rminos de precisi√≥n de decisiones, sino tambi√©n en objetivos humanos como el aprendizaje y la colaboraci√≥n humano-IA. Se realizaron dos experimentos con 316 y 964 participantes, quienes deb√≠an recomendar rutinas de ejercicios a perfiles ficticios, recibiendo distintos tipos de ayuda de la IA (explicaciones, recomendaciones, asistencia bajo demanda). Los resultados mostraron que las pol√≠ticas optimizadas con RL aumentan la exactitud y, en algunos casos, tambi√©n el aprendizaje de los participantes.</p>
                    
                    <h3>2. Problemas encontrados</h3>
                    <ul>
                        <li>La mayor√≠a de sistemas de IA para apoyo en decisiones se enfocan √∫nicamente en la precisi√≥n, ignorando factores humanos como la motivaci√≥n, aprendizaje y confianza.</li>
                        <li>Existe el riesgo de sobredependencia de la IA (overreliance), que puede reducir el compromiso cognitivo de las personas.</li>
                        <li>M√©todos tradicionales (como recomendaciones fijas) no logran adaptarse a diferentes perfiles cognitivos, especialmente en usuarios con baja o alta "Necesidad de Cognici√≥n (NFC)".</li>
                    </ul>
                    
                    <h3>3. Objetivo general y espec√≠ficos</h3>
                    
                    <h4>Objetivo general:</h4>
                    <p>Optimizar la interacci√≥n humano-IA en la toma de decisiones mediante aprendizaje por refuerzo offline, considerando tanto precisi√≥n como objetivos humanos (aprendizaje y disfrute de la tarea).</p>
                    
                    <h4>Objetivos espec√≠ficos:</h4>
                    <ol>
                        <li>Dise√±ar un sistema de apoyo a la decisi√≥n basado en RL capaz de adaptar el tipo de asistencia de IA seg√∫n el usuario.</li>
                        <li>Evaluar el impacto de las pol√≠ticas de RL sobre la precisi√≥n de las decisiones.</li>
                        <li>Medir si estas pol√≠ticas mejoran el aprendizaje humano y la percepci√≥n de colaboraci√≥n con la IA.</li>
                        <li>Comparar los resultados con enfoques tradicionales (explicaciones est√°ticas, recomendaciones fijas, etc.).</li>
                    </ol>
                    
                    <h3>4. Marco te√≥rico</h3>
                    <p><strong>Alan Turing (1950)</strong> plante√≥ si las m√°quinas pod√≠an pensar ‚Üí <strong>Miller (2021)</strong> retoma esa idea al proponer que la IA no solo recomiende, sino que muestre evidencias para estimular el razonamiento humano.</p>
                    
                    <p><strong>Herbert Simon y Allen Newell (1950-70)</strong> ve√≠an la IA como apoyo en la resoluci√≥n de problemas complejos ‚Üí <strong>Noti & Chen (2022)</strong> y <strong>Ma et al. (2020)</strong> contin√∫an esa visi√≥n al destacar la colaboraci√≥n humano-IA para tomar mejores decisiones.</p>
                    
                    <p><strong>Marvin Minsky (1960-80)</strong> buscaba imitar procesos cognitivos humanos ‚Üí <strong>Deci & Ryan (1985)</strong> y <strong>Cacioppo & Petty (1982)</strong> ampl√≠an esta perspectiva mostrando c√≥mo la motivaci√≥n y la necesidad de cognici√≥n determinan c√≥mo las personas usan la IA.</p>
                    
                    <p>En conjunto, la disciplina actual de IA centrada en el humano es una evoluci√≥n directa de los principios fundacionales de la IA: de m√°quinas que imitan la mente a sistemas que optimizan la interacci√≥n humano-IA para mejorar precisi√≥n, aprendizaje y motivaci√≥n.</p>
                    
                    <h3>5. Metodolog√≠a</h3>
                    <ul>
                        <li><strong>Dise√±o:</strong> Experimentos controlados online con dos muestras (N=316 y N=964).</li>
                        <li><strong>Tarea:</strong> Recomendaci√≥n de ejercicios a perfiles ficticios con distintos objetivos (perder peso, flexibilidad, etc.).</li>
                        <li><strong>Condiciones de IA:</strong>
                            <ul>
                                <li>Sin IA</li>
                                <li>Recomendaci√≥n + explicaci√≥n</li>
                                <li>Explicaci√≥n sola</li>
                                <li>Asistencia bajo demanda</li>
                            </ul>
                        </li>
                        <li><strong>Datos:</strong> Se recogieron decisiones de los participantes y se entrenaron pol√≠ticas de RL con esos datos.</li>
                        <li><strong>Evaluaci√≥n:</strong> Comparaci√≥n de pol√≠ticas optimizadas vs. enfoques tradicionales en t√©rminos de:
                            <ul>
                                <li>Precisi√≥n en la decisi√≥n</li>
                                <li>Aprendizaje (tests posteriores)</li>
                                <li>Disfrute y confianza reportados</li>
                            </ul>
                        </li>
                    </ul>
                    
                    <h3>6. Resultados</h3>
                    
                    <h4>Objetivo general</h4>
                    <p>Optimizar la interacci√≥n humano-IA en la toma de decisiones mediante aprendizaje por refuerzo offline, considerando tanto precisi√≥n como objetivos humanos (aprendizaje y disfrute).</p>
                    <p><strong>‚úÖ Resultado:</strong> S√≠ se logr√≥ en parte. El RL offline mejor√≥ la precisi√≥n y gener√≥ pol√≠ticas m√°s adaptativas. Sin embargo, optimizar el aprendizaje humano fue m√°s dif√≠cil: se logr√≥ solo en ciertos grupos (los de baja NFC).</p>
                    
                    <h4>üìå Objetivo espec√≠fico 1:</h4>
                    <p>Dise√±ar un sistema de apoyo a la decisi√≥n basado en RL capaz de adaptar el tipo de asistencia de IA seg√∫n el usuario.</p>
                    <p><strong>‚úÖ Resultado:</strong> Se desarroll√≥ un sistema con 4 tipos de ayuda (sin IA, recomendaci√≥n+explicaci√≥n, solo explicaci√≥n, bajo demanda) y RL eligi√≥ la mejor seg√∫n contexto y perfil cognitivo.</p>
                    
                    <h4>üìå Objetivo espec√≠fico 2:</h4>
                    <p>Evaluar el impacto de las pol√≠ticas de RL sobre la precisi√≥n de las decisiones.</p>
                    <p><strong>‚úÖ Resultado:</strong> Las pol√≠ticas optimizadas con RL superaron significativamente a los m√©todos tradicionales (ej. recomendaciones fijas) en exactitud.</p>
                    
                    <h5>üîπ ¬øQu√© son "pol√≠ticas" en RL?</h5>
                    <p>Una pol√≠tica (policy) en RL es la estrategia que sigue el agente para decidir qu√© acci√≥n tomar en cada situaci√≥n.</p>
                    <p>En este art√≠culo, la "acci√≥n" es qu√© tipo de ayuda ofrecer al usuario durante la tarea de toma de decisiones.</p>
                    
                    <p><strong>Ejemplos de acciones que forman parte de la pol√≠tica:</strong></p>
                    <ul>
                        <li>Dar una recomendaci√≥n con explicaci√≥n.</li>
                        <li>Dar solo una explicaci√≥n.</li>
                        <li>Dar ayuda bajo demanda.</li>
                        <li>Dar ninguna ayuda.</li>
                    </ul>
                    
                    <p>La pol√≠tica aprendida le dice al sistema en qu√© momento y a qu√© tipo de usuario conviene aplicar cada forma de ayuda.</p>
                    
                    <h5>üîπ ¬øQu√© se hizo en el experimento?</h5>
                    <ol>
                        <li>Primero recolectaron datos de decisiones humanas bajo distintos tipos de ayuda.</li>
                        <li>Con esos datos, entrenaron un modelo de RL offline, que busc√≥ la pol√≠tica √≥ptima: es decir, la combinaci√≥n de ayudas que maximizaba la precisi√≥n de las decisiones.</li>
                        <li>Luego probaron esa pol√≠tica optimizada con nuevos participantes para ver si funcionaba mejor que los m√©todos tradicionales (ejemplo: siempre dar explicaci√≥n fija).</li>
                    </ol>
                    
                    <h5>üîπ ¬øC√≥mo se logr√≥ el resultado?</h5>
                    <p><strong>Resultado obtenido:</strong> las pol√≠ticas optimizadas con RL lograron mayor precisi√≥n en la toma de decisiones que las pol√≠ticas tradicionales (ejemplo: siempre dar recomendaci√≥n o siempre dar explicaci√≥n).</p>
                    <p>Es decir, la IA aprendi√≥ que no hay una sola forma universal de ayudar, sino que la mejor estrategia es adaptar el tipo de ayuda a cada contexto y perfil cognitivo del usuario.</p>
                    
                    <h4>üìå Objetivo espec√≠fico 3:</h4>
                    <p>Medir si estas pol√≠ticas mejoran el aprendizaje humano.</p>
                    <p><strong>‚ö†Ô∏è Resultado parcial:</strong> El aprendizaje mejor√≥ en personas con baja necesidad de cognici√≥n (NFC), pero no en las de alta NFC. Es m√°s complejo optimizar aprendizaje que precisi√≥n.</p>
                    
                    <h4>üìå Objetivo espec√≠fico 4:</h4>
                    <p>Comparar los resultados con enfoques tradicionales.</p>
                    <p><strong>‚úÖ Resultado:</strong> El RL fue mejor que los m√©todos cl√°sicos en precisi√≥n. En aprendizaje, el RL solo super√≥ en algunos casos, mostrando que a√∫n hay limitaciones.</p>
                    
                    <h3>7. Implicaciones para la Simbiosis Humano-IA</h3>
                    <p>Este estudio refuerza la importancia de considerar <strong>objetivos humanos</strong> m√°s all√° de la precisi√≥n algor√≠tmica. El aprendizaje por refuerzo offline demuestra que es posible optimizar tanto la eficiencia como el desarrollo cognitivo humano, aunque con limitaciones seg√∫n el perfil cognitivo del usuario.</p>
                    
                    <p>La investigaci√≥n conecta directamente con los principios de <strong>delegaci√≥n bidireccional</strong> y <strong>recalibraci√≥n de agencia</strong> discutidos en el marco te√≥rico principal, mostrando c√≥mo la IA puede adaptarse din√°micamente a las necesidades humanas espec√≠ficas, creando una verdadera simbiosis cognitiva.</p>
                </section>
            </div>

            <!-- Columna Derecha: Resumen -->
            <div class="column">
                <section class="section">
                    <h2>Resumen Ejecutivo</h2>
                    
                    <h3>1. Resumen</h3>
                    <p><strong>Offline RL</strong> para optimizar decisiones humano-IA. 2 experimentos (316 y 964 participantes) con recomendaciones de ejercicios. Resultado: mayor exactitud y aprendizaje en algunos casos.</p>
                    
                    <h3>2. Problemas</h3>
                    <ul>
                        <li>Sistemas IA solo enfocados en precisi√≥n</li>
                        <li>Riesgo de sobredependencia (overreliance)</li>
                        <li>M√©todos tradicionales no se adaptan a perfiles cognitivos</li>
                    </ul>
                    
                    <h3>3. Objetivos</h3>
                    <p><strong>General:</strong> Optimizar interacci√≥n humano-IA con RL offline.</p>
                    <p><strong>Espec√≠ficos:</strong></p>
                    <ol>
                        <li>Sistema RL adaptativo</li>
                        <li>Evaluar impacto en precisi√≥n</li>
                        <li>Medir aprendizaje humano</li>
                        <li>Comparar con m√©todos tradicionales</li>
                    </ol>
                    
                    <h3>4. Marco Te√≥rico</h3>
                    <p><strong>Turing ‚Üí Miller:</strong> IA que estimula razonamiento humano</p>
                    <p><strong>Simon & Newell ‚Üí Noti & Chen:</strong> Colaboraci√≥n humano-IA</p>
                    <p><strong>Minsky ‚Üí Deci & Ryan:</strong> Motivaci√≥n y cognici√≥n en uso de IA</p>
                    
                    <h3>5. Metodolog√≠a</h3>
                    <ul>
                        <li>Experimentos online (N=316, N=964)</li>
                        <li>Tarea: recomendaci√≥n de ejercicios</li>
                        <li>4 condiciones de IA</li>
                        <li>Pol√≠ticas RL vs. tradicionales</li>
                    </ul>
                    
                    <h3>6. Resultados</h3>
                    <p><strong>‚úÖ Precisi√≥n:</strong> RL super√≥ m√©todos tradicionales</p>
                    <p><strong>‚ö†Ô∏è Aprendizaje:</strong> Mejor√≥ solo en baja NFC</p>
                    <p><strong>‚úÖ Adaptabilidad:</strong> Sistema con 4 tipos de ayuda</p>
                    <p><strong>‚úÖ Comparaci√≥n:</strong> RL mejor en precisi√≥n, limitado en aprendizaje</p>
                    
                    <h3>7. Implicaciones</h3>
                    <p>Refuerza importancia de <strong>objetivos humanos</strong> m√°s all√° de precisi√≥n algor√≠tmica. Conecta con <strong>delegaci√≥n bidireccional</strong> y <strong>recalibraci√≥n de agencia</strong> para crear simbiosis cognitiva.</p>
                </section>
            </div>
        </div>

        <footer class="footer">
            <p>Estudio de caso: Municipio Sueco | Metodolog√≠a Gioia | An√°lisis Cualitativo | Offline RL Research</p>
        </footer>
    </div>
</body>
</html>
