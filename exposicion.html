<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Simbiosis Humano-IA - Exposición Académica</title>
    <link rel="stylesheet" href="exposicion.css">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
</head>a
<body>
    <div class="container">
        <header class="main-header">
            <h1>Simbiosis humano-IA</h1>
            <h2>Explorando la delegación y la recalibración constante de la agencia</h2>
            <h3>A través de IA generativa</h3>
        </header>

        <div class="content-wrapper">
            <!-- Resumen Ejecutivo de la Investigación -->
            <div class="executive-summary">
                <div class="summary-container">
                    <h2>Resumen Ejecutivo de la Investigación</h2>
                    
                    <div class="summary-section">
                        <h3>Problema (1)</h3>
                        <p>En el municipio sueco, las tareas administrativas son muy repetitivas y consumen tiempo (ej. transcripción de actas, redacción de informes, procesamiento de solicitudes). Surge el problema de cómo integrar la IA generativa (Copilot) para aumentar la eficiencia sin perder confianza, transparencia ni equidad.</p>
                    </div>
                    
                    <div class="summary-section">
                        <h3>Objetivos (2)</h3>
                        <p><strong>Objetivo General:</strong> Analizar el impacto de la implementación de IA generativa (Copilot) en los procesos administrativos de un municipio sueco, considerando sus efectos en la eficiencia, la innovación, la confianza y la redefinición de roles en el sector público.</p>
                        
                        <p><strong>Objetivos Específicos:</strong></p>
                        <ul>
                            <li><strong>Eficiencia:</strong> Evaluar el grado de eficiencia alcanzado mediante la delegación de tareas administrativas a Copilot</li>
                            <li><strong>Innovación:</strong> Examinar cómo Copilot promueve o limita la innovación en los procesos de trabajo</li>
                            <li><strong>Confianza:</strong> Analizar las percepciones de los empleados respecto a la confianza en los resultados generados por Copilot</li>
                            <li><strong>Roles:</strong> Identificar los cambios en los roles y dinámicas laborales derivados de la introducción de Copilot</li>
                            <li><strong>Gobernanza:</strong> Explorar los desafíos éticos, organizacionales y de gobernanza que emergen con la implementación de IA generativa</li>
                        </ul>
                    </div>
                    
                    <div class="summary-section">
                        <h3>Marco Teórico (3 y 4)</h3>
                        <p>Desde los padres de la IA, <strong>Turing</strong> preguntaba si una máquina puede "pensar"; esto se refleja hoy en si Copilot realmente ayuda a tomar decisiones o solo imita un asistente.</p>
                        <p><strong>John McCarthy</strong> definió la IA como máquinas inteligentes, y en tu caso Copilot actúa como tal al redactar informes o responder consultas.</p>
                        <p>Con <strong>Minsky</strong>, la idea de redes neuronales se plasma en la IA generativa de Copilot que aprende patrones de texto.</p>
                        <p><strong>Simon & Newell</strong>, con la resolución lógica, se relacionan con Copilot procesando datos y generando salidas organizadas.</p>
                        <p><strong>Wiener</strong>, con la cibernética, conecta con la retroalimentación constante entre usuarios y Copilot, que se recalibra según la interacción.</p>
                        <p>Autores contemporáneos como <strong>Kaplan, Haenlein, Davenport y Mikalef</strong> extienden estas ideas al terreno actual: confianza, ética, gobernanza y estrategia digital en instituciones públicas.</p>
                        
                        <h4>Fundamentos de la Teoría de la Información</h4>
                        <p>La <strong>Teoría de la Información</strong>, desarrollada por <strong>Claude Shannon</strong>, proporciona el marco matemático fundamental para entender cómo se procesa, transmite y almacena la información en sistemas complejos. En el contexto de la IA generativa como Copilot, esta teoría explica:</p>
                        <ul>
                            <li><strong>Entropía de la información:</strong> Mide la incertidumbre y el contenido informativo de los mensajes que procesa la IA</li>
                            <li><strong>Codificación eficiente:</strong> Cómo la IA optimiza la representación de datos para maximizar la información útil</li>
                            <li><strong>Canales de comunicación:</strong> Los procesos de interacción humano-IA como sistemas de transmisión de información</li>
                            <li><strong>Redundancia y ruido:</strong> Cómo la IA filtra información irrelevante y mantiene la coherencia en sus respuestas</li>
                        </ul>
                        <p>Esta perspectiva teórica permite entender la colaboración humano-IA como un <strong>sistema de comunicación bidireccional</strong> donde la información fluye, se procesa y se retroalimenta continuamente, optimizando tanto la eficiencia algorítmica como la comprensión humana.</p>
                    </div>
                    
                    <div class="summary-section">
                        <h3>Metodología de investigación (5)</h3>
                        <p>Decidiste usar un estudio de caso (el municipio sueco) y entrevistas semiestructuradas con empleados que usan Copilot. Esto te permite recoger sus percepciones reales: algunos lo ven como un <strong>"secretario eficiente"</strong>, otros como un <strong>"coautor"</strong>, y otros sienten temor de perder autonomía.</p>
                    </div>
                    
                    <div class="summary-section">
                        <h3>Metodología de implementación – IA (6)</h3>
                        <p>Aquí describes cómo se integra Copilot en la práctica:</p>
                        <ul>
                            <li><strong>Licencias limitadas</strong> → genera desigualdad de acceso.</li>
                            <li><strong>Automatiza lo rutinario</strong> (transcripción, síntesis) → libera tiempo humano.</li>
                            <li><strong>Requiere supervisión humana</strong> para temas sensibles (privacidad, decisiones críticas).</li>
                        </ul>
                        <p>La implementación incluye capacitaciones y pruebas piloto, lo cual muestra que la adopción no es solo técnica, sino también cultural.</p>
                    </div>
                    
                    <div class="summary-section">
                        <h3>Resultados (7)</h3>
                        <p><strong>Resumen de Hallazgos por Objetivo:</strong></p>
                        <ul>
                            <li><strong>Eficiencia:</strong> Copilot permitió ahorrar tiempo en tareas repetitivas, aunque la revisión y corrección de salidas demandó tiempo adicional, matizando la percepción de eficiencia total.</li>
                            <li><strong>Innovación:</strong> La herramienta facilitó nuevas formas de trabajo y generación rápida de borradores, pero algunos resultados fueron percibidos como "estándar" o "aburridos", limitando la creatividad.</li>
                            <li><strong>Confianza:</strong> Se evidenció confianza moderada: útil para tareas mecánicas, pero con dudas en contextos sensibles, manteniendo la necesidad de supervisión humana.</li>
                            <li><strong>Roles:</strong> Se observó reconfiguración de roles: Copilot como "asistente" o "coautor", pero con preocupaciones sobre pérdida de autonomía y desigualdad en acceso a licencias.</li>
                            <li><strong>Gobernanza:</strong> Emergieron desafíos clave: desigualdad de acceso, privacidad de datos, gobernanza organizacional y dependencia tecnológica.</li>
                        </ul>
                        <p>Los resultados demuestran que la IA es útil pero requiere gobernanza ética y supervisión humana para una implementación sostenible en el sector público.</p>
                    </div>
                </div>
            </div>
            
            <div class="column">
                <section class="section">
                    <h2>Resumen</h2>
                    <p>Este estudio examina la implementación de <strong>inteligencia artificial generativa</strong> en el sector público, aplicando un enfoque de <strong>pensamiento sistémico</strong> para analizar los procesos de delegación dinámica y recalibración de agencia entre humanos y máquinas. La investigación se fundamenta en el <strong>modelado</strong> de sistemas híbridos y la <strong>simulación</strong> de escenarios de colaboración humano-IA.</p>
                    
                    <p>Mediante un <strong>estudio de caso cualitativo</strong> en un municipio sueco, se analiza la colaboración simbiótica que emerge cuando los sistemas de IA generativa se integran en entornos organizacionales complejos. El enfoque metodológico combina <strong>análisis cualitativo</strong> con técnicas de <strong>optimización</strong> de procesos, utilizando la metodología Gioia para la codificación y análisis de datos.</p>
                    
                    <p>El estudio propone un <strong>marco conceptual</strong> basado en <strong>delegación bidireccional</strong> y <strong>recalibración de agencia</strong>, posicionando la IA generativa como una <strong>herramienta de apoyo a la toma de decisiones</strong> que complementa las capacidades humanas. Los resultados evidencian la evolución hacia sistemas híbridos que optimizan tanto la eficiencia algorítmica como la supervisión humana, estableciendo un modelo de <strong>sistemas blandos</strong> adaptativos para la gobernanza pública.</p>
                </section>

                <section class="section">
                    <h2>Planteamiento del Problema y Objetivos</h2>
                    <h3>Problema Central</h3>
                    <p>La distribución de agencia entre humanos y máquinas presenta tensiones fundamentales entre la eficiencia algorítmica y la necesidad de supervisión humana. Esta tensión se intensifica en el sector público, donde las decisiones tienen implicaciones directas en la vida ciudadana.</p>
                    
                    <h3>Justificación Contextual</h3>
                    <p>La modernización del sector público mediante IA genera dilemas éticos complejos que requieren marcos conceptuales robustos para guiar la implementación responsable de estas tecnologías.</p>
                    
                    <h3>Objetivo General</h3>
                    <p>Analizar el impacto de la implementación de la inteligencia artificial generativa (Copilot) en los procesos administrativos de un municipio sueco, considerando sus efectos en la eficiencia, la innovación, la confianza y la redefinición de roles en el sector público.</p>
                    
                    <h3>🎯 Objetivos Específicos</h3>
                    <ol>
                        <li><strong>Evaluar el grado de eficiencia</strong> alcanzado mediante la delegación de tareas administrativas a Copilot, en comparación con los métodos tradicionales.</li>
                        <li><strong>Examinar de qué manera Copilot promueve o limita la innovación</strong> en los procesos de trabajo del municipio.</li>
                        <li><strong>Analizar las percepciones de los empleados</strong> respecto a la confianza en los resultados generados por Copilot y su influencia en la toma de decisiones.</li>
                        <li><strong>Identificar los cambios en los roles y dinámicas laborales</strong> derivados de la introducción de Copilot en la gestión pública.</li>
                        <li><strong>Explorar los desafíos éticos, organizacionales y de gobernanza</strong> que emergen con la implementación de inteligencia artificial generativa en el sector público.</li>
                    </ol>
                </section>

                <section class="section">
                    <h2>Marco Teórico</h2>
                    <h3>Fundamentos de la Inteligencia Artificial</h3>
                    <p>La Inteligencia Artificial (IA) no nació de un solo científico, sino de un grupo de pensadores y disciplinas que se unieron en los años 40–50 y se consolidaron como campo formal en 1956. Desde entonces, la IA se ha definido como una disciplina de la informática encargada de desarrollar sistemas y programas capaces de realizar tareas que normalmente requieren inteligencia humana, como el razonamiento, la toma de decisiones, el aprendizaje y la adaptación.</p>
                    
                    <p>En el presente estudio, se aborda la IA desde una perspectiva cognitiva y simbiótica, enfocada en su capacidad para colaborar con humanos en entornos complejos como el sector público.</p>
                    
                    <h3>Herbert Simon y la Racionalidad Limitada</h3>
                    <p>Esta visión se articula con los aportes de <strong>Herbert Simon</strong>, citado en el documento base de esta investigación, quien fue pionero en el estudio de la toma de decisiones administrativas y en el desarrollo de modelos computacionales que simulan procesos cognitivos humanos. Su teoría de la <strong>racionalidad limitada</strong> no solo transformó la gestión pública, sino que también sentó las bases para el diseño de sistemas inteligentes capaces de colaborar con humanos en entornos inciertos.</p>
                    
                    <p>En este marco, la IA no se concibe como sustituto del juicio humano, sino como <strong>amplificador cognitivo</strong>, capaz de extender la capacidad de análisis, síntesis y decisión en contextos organizacionales.</p>
                    
                    <h3>Modelos de Delegación en Sistemas Humano-IA</h3>
                    <p>Para comprender la dinámica de colaboración entre humanos y sistemas de inteligencia artificial, es fundamental analizar los modelos de delegación que estructuran dicha interacción. Diversos estudios han identificado tres tipos principales de delegación: de humano a IA, de IA a humano, y bidireccional. Estos modelos permiten mapear cómo se distribuyen las responsabilidades en sistemas inteligentes y cómo se recalibra la agencia en función del contexto, la competencia y el aprendizaje mutuo.</p>
                    
                    <div class="image-container">
                        <h4>Tabla 2. Tipos de delegación en sistemas humano-IA: definición y referencias clave</h4>
                        <img src="qwe123.png" alt="Tabla de tipos de delegación en sistemas humano-IA" class="methodology-image">
                    </div>
                    
                    <h3>Análisis de los Modelos de Delegación</h3>
                    <p>La tabla sintetiza los tres modelos de delegación más relevantes en el campo de la interacción humano-IA.</p>
                    
                    <ul>
                        <li>En la <strong>delegación Humano-IA</strong>, el humano asigna tareas al sistema, manteniendo supervisión parcial.</li>
                        <li>En la <strong>delegación IA-Humano</strong>, el sistema transfiere decisiones al humano, evaluando su competencia.</li>
                        <li>En la <strong>delegación bidireccional</strong>, ambos actores colaboran activamente, ajustando sus roles según el flujo de trabajo.</li>
                    </ul>
                    
                    <p>Estos modelos, respaldados por autores como Shrestha, Fügener, Carroll y Lebovitz, constituyen la base conceptual para entender la <strong>simbiosis humano-IA</strong>. En particular, la delegación bidireccional representa el ideal de colaboración adaptativa, donde la agencia se distribuye dinámicamente y se retroalimenta en tiempo real. Este marco teórico se conecta directamente con los principios de la <strong>cibernética organizacional</strong>, al considerar la interacción como un sistema auto-regulado, sensible al entorno y capaz de evolucionar.</p>
                    
                    <h3>Recalibración de Agencia</h3>
                    <p>Basada en la teoría de la racionalidad limitada, la recalibración permite ajustes dinámicos en la distribución de responsabilidades según el contexto y el desempeño del sistema.</p>
                    
                    <h3>Simbiosis Humano-IA</h3>
                    <p>Inspirada en la cibernética organizacional, esta relación mutuamente beneficiosa optimiza las capacidades tanto humanas como artificiales, creando sinergias que superan las limitaciones individuales.</p>
                    
                    <h3>Conceptos</h3>
                    <p><strong>Holmström y Carroll (2024)</strong> ilustran aún más este punto de vista al enfatizar la perspectiva de una relación mutuamente interdependiente en lugar de una de exclusión, y al enfatizar los beneficios sinérgicos. La perspectiva tradicional sugiere que la IA es superior a los humanos en el procesamiento del lenguaje y el reconocimiento de patrones <strong>(Shrestha et al., 2019)</strong>.</p>
                    
                    <p>Por lo tanto, en el ámbito médico, por ejemplo, se utilizaron agentes de IA para filtrar alternativas y reducirlas, mientras que el agente humano, es decir, el profesional médico, evaluaba esas opciones y tomaba la decisión final como una forma de aumento participativo <strong>(Lebovitz et al., 2022)</strong>. En consecuencia, el desarrollo de la IA puede considerarse una dinámica dialéctica y mutuamente dependiente entre los humanos y la IA <strong>(Van den Broek et al., 2021; Shrestha et al., 2019)</strong>.</p>
                    
                    <p>Si bien se alaba la capacidad de la IA para analizar grandes volúmenes de datos y reconocer patrones, la contextualización, el razonamiento ético y la reflexividad crítica que proporciona sentido solo se manifiestan en humanos <strong>(Sundberg y Holmström, 2024)</strong>. Este tipo de relación simbiótica es una vía que impulsaría aún más el proceso de aprendizaje, perfeccionando así las habilidades algorítmicas junto con la inteligencia humana <strong>(Van den Broek et al., 2021)</strong>.</p>
                    
                    <p>Por esto <strong>Kaplan & Haenlein</strong> definen la IA como la capacidad de interpretar datos y adaptarse a objetivos específicos, retomando la discusión iniciada por <strong>Alan Turing</strong>, quien planteó la pregunta sobre qué significa realmente considerar a una máquina inteligente mediante su Test de Turing.</p>
                    
                    <p><strong>Brynjolfsson & McAfee</strong> destacan el impacto económico y organizacional de la IA, ampliando la visión de <strong>John McCarthy</strong>, quien acuñó el término Inteligencia Artificial y la presentó como la ciencia de construir máquinas inteligentes.</p>
                    
                    <p>Las ideas de <strong>Marvin Minsky</strong> sobre la mente como proceso computable y sus avances en redes neuronales encuentran eco en los trabajos de <strong>Brynjolfsson, McAfee y Davenport</strong>, quienes analizan cómo el aprendizaje automático transforma la productividad y la toma de decisiones.</p>
                    
                    <p>Los aportes de <strong>Herbert Simon y Allen Newell</strong> en la resolución lógica de problemas se reflejan en las reflexiones de <strong>Davenport y Mittelstadt</strong>, que discuten los límites y riesgos de delegar decisiones a los algoritmos, subrayando la importancia de la transparencia y la rendición de cuentas.</p>
                    
                    <p>La visión de <strong>Norbert Wiener</strong> sobre la cibernética y los sistemas de retroalimentación humano-máquina se prolonga en los estudios de <strong>Kaplan, Haenlein y Mikalef</strong>, quienes analizan la necesidad de confianza, gobernanza y ajuste continuo en los ecosistemas híbridos de colaboración humano-IA.</p>
                </section>
            </div>

            <div class="column">
                <section class="section">
                    <h2>Gobernanza Ética</h2>
                    <p>Los principios fundamentales incluyen la <strong>transparencia</strong> en los procesos algorítmicos, la <strong>responsabilidad compartida</strong> entre humanos y sistemas, y la <strong>equidad organizacional</strong> en la distribución de beneficios y riesgos.</p>
                    
                    <h3>Conexiones Conceptuales</h3>
                    <ul>
                        <li>Automatización híbrida: combinación de control humano y automático</li>
                        <li>Ingeniería de prompts: optimización de interacciones humano-IA</li>
                        <li>Ética algorítmica: marcos para decisiones justas y transparentes</li>
                    </ul>
                </section>

                <section class="section">
                    <h2>Metodología</h2>
                    
                    <h3>1. Metodología de Investigación</h3>
                    
                    <h4>Enfoques</h4>
                    <p>La presente investigación adopta un <strong>enfoque cualitativo</strong> para analizar la interacción entre humanos y sistemas de inteligencia artificial generativa en el sector público. Se busca comprender cómo se distribuyen las responsabilidades entre ambos actores y cómo se ajusta la agencia humana en función del desempeño algorítmico.</p>
                    
                    <p>Se utilizó un <strong>estudio de caso</strong> en un municipio sueco que implementó Microsoft Copilot como herramienta de IA generativa en tareas administrativas. La recolección de datos se realizó mediante <strong>entrevistas semiestructuradas</strong> a empleados públicos, enfocadas en sus experiencias de delegación, confianza y colaboración con la IA.</p>
                    
                    <p>Para el análisis, se aplicó la <strong>metodología Gioia</strong>, que permite construir teoría a partir de datos empíricos mediante codificación abierta, axial y agregada. Este enfoque facilitó la identificación de conceptos de primer orden (acciones observadas), categorías de segundo orden (interpretaciones organizacionales), y dimensiones agregadas (constructos teóricos).</p>
                    
                    <p>El comportamiento observado en la interacción humano-IA refleja principios de la <strong>cibernética organizacional</strong>, especialmente en lo que respecta a la <strong>retroalimentación continua</strong> y el <strong>control adaptativo</strong>. Los participantes ajustaban sus decisiones en función de las respuestas de la IA, y la IA, a su vez, modificaba sus recomendaciones según el contexto y el historial de uso. Este ciclo de ajuste dinámico constituye un sistema auto-regulado, alineado con los postulados de <strong>Norbert Wiener</strong> sobre control y comunicación en sistemas inteligentes.</p>
                    
                    <h3>2. Metodología de Implementación – IA (Características)</h3>
                    
                    <h4>Tipo de IA utilizada</h4>
                    <p><strong>IA generativa</strong> (Microsoft Copilot) basada en modelos de lenguaje de gran escala (LLM), con capacidad de procesar lenguaje natural, redactar documentos y asistir en tareas administrativas.</p>
                    
                    <h4>Características técnicas</h4>
                    <ul>
                        <li><strong>Automatización:</strong> Delegación de tareas repetitivas y de bajo valor cognitivo</li>
                        <li><strong>Aumentación:</strong> Asistencia en toma de decisiones y apoyo en creatividad (redacción de informes, síntesis de datos)</li>
                        <li><strong>Retroalimentación continua:</strong> La herramienta aprende y se ajusta a través del uso</li>
                        <li><strong>Transparencia limitada:</strong> Dependencia de la explicabilidad y confianza en los resultados</li>
                    </ul>
                    
                    <h4>Proceso de integración</h4>
                    <ul>
                        <li><strong>Fase piloto:</strong> Uso experimental en administración municipal</li>
                        <li><strong>Asignación de licencias:</strong> Distribución restringida, generando dinámicas de acceso desigual</li>
                        <li><strong>Pruebas de usabilidad:</strong> Talleres, sesiones de aprendizaje y experimentación</li>
                        <li><strong>Evaluación de desempeño:</strong> Medición de eficiencia, ahorro de tiempo y calidad de tareas</li>
                    </ul>
                    
                    <h4>Consideraciones éticas y factores de éxito</h4>
                    <ul>
                        <li><strong>Privacidad de datos:</strong> Anonimización de información sensible</li>
                        <li><strong>Supervisión humana:</strong> Usuario mantiene responsabilidad en decisiones críticas</li>
                        <li><strong>Capacitación:</strong> Alfabetización digital y prompt engineering</li>
                        <li><strong>Cultura organizacional:</strong> Apertura al cambio tecnológico</li>
                    </ul>
                    
                    <h3>Análisis Inductivo y Mapa Conceptual</h3>
                    <p>Como parte del análisis cualitativo, se utilizó un enfoque inductivo para identificar patrones emergentes en la interacción humano-IA dentro el sector público. Para ello, se construyó un mapa conceptual que sintetiza las dimensiones clave observadas durante el estudio de caso. Este diagrama representa las categorías temáticas que surgieron del proceso de codificación, alineadas con la metodología Gioia.</p>
                    
                    <div class="image-container">
                        <h4>Dimensiones emergentes en la interacción humano-IA</h4>
                        <img src="asdf.png" alt="Mapa conceptual de dimensiones emergentes en la interacción humano-IA" class="methodology-image">
                    </div>
                    
                    <h3>Análisis de Datos y Metodología Gioia</h3>
                    <p>Siguiendo los pasos sistemático-inductivos tradicionales de la metodología Gioia, nuestro análisis combina una profunda interacción con los informantes en un enfoque iterativo de construcción teórica <strong>(Gioia et al., 2013)</strong>. Parte del supuesto de que los participantes son "agentes con conocimiento" capaces de expresar con elocuencia sus experiencias y la construcción de significado.</p>
                    
                    <p>Las entrevistas semiestructuradas se realizaron en un municipio sueco para comprender cómo los empleados integran e interpretan Microsoft Copilot en sus operaciones diarias. Esta atención a las palabras de los informantes mejoró nuestra codificación in vivo y nos permitió capturar las expresiones de los participantes sin imponer preconcepciones teóricas prematuras <strong>(Gioia et al., 2013; Corley y Gioia, 2004)</strong>.</p>
                    
                    <h4>Ejemplo Práctico de Codificación</h4>
                    <p>Un hallazgo revelador emergió durante la codificación: los empleados se referían a Copilot de manera variable según su función percibida. En ocasiones lo consideraban una <strong>"secretaria de oficina más eficiente"</strong> para tareas rutinarias, mientras que en otras lo describían como <strong>"profesor o coautor"</strong> para funciones creativas. Esta variabilidad en las etiquetas sugiere que Copilot opera bajo múltiples roles simultáneos, desde resolver tareas prácticas cotidianas hasta facilitar colaboraciones más amplias.</p>
                    
                    <h3>Proceso de Codificación Gioia</h3>
                    <p>Tras realizar la codificación in vivo, desarrollamos conjuntos preliminares de códigos de primer orden. Para mejorar la credibilidad y el rigor del análisis, cada autor analizó de forma independiente la codificación in vivo <strong>(Denzin, 1978; Patton, 1999)</strong>. Uno generó 105 códigos a partir de 641 citas, mientras que el otro 176 códigos a partir de 460. Estos conjuntos se triangularon mediante comparaciones iterativas.</p>
                    
                    <p>Los temas de segundo orden se presentan como ideas estrechamente situadas y conceptualmente relacionadas, representativas de ideas subyacentes más abstractas. Se siguió la guía de <strong>Pratt (2009)</strong> sobre las "citas de poder", utilizadas para mostrar datos en lugar de simplemente describirlos, creando así una cadena de evidencia que destaca cómo las voces de los informantes informan críticamente nuestras perspectivas teóricas.</p>
                    
                    <p>El proceso culminó en la derivación de 15 conceptos de primer orden, sus correspondientes temas de segundo orden y cinco dimensiones agregadas, generando así un resultado preliminar del análisis de Gioia que estructura el modelo conceptual propuesto.</p>
                    
                    <p>El diagrama refleja esta progresión inductiva, mostrando cómo la adopción de IA generativa impacta múltiples niveles organizacionales: desde la automatización de tareas hasta la redefinición de roles humanos, pasando por la necesidad de estrategias sostenibles y protocolos éticos. Cada categoría representa un nodo de análisis que contribuye a entender la simbiosis humano-IA como un sistema adaptativo, distribuido y en constante recalibración.</p>
                    
                    <h3>Dimensiones Emergentes</h3>
                    <ul>
                        <li>Transformación laboral y nuevas competencias</li>
                        <li>Gobernanza ética en sistemas híbridos</li>
                        <li>Ecosistemas híbridos de colaboración</li>
                        <li>Construcción de confianza humano-IA</li>
                        <li>Estrategias para implementación sostenible</li>
                    </ul>
                </section>

                <section class="section">
                    <h2>📊 Resultados</h2>
                    
                    <h3>Objetivo 1: Evaluar el grado de eficiencia alcanzado mediante la delegación de tareas administrativas a Copilot</h3>
                    <p>Los resultados muestran que Copilot permitió ahorrar tiempo en tareas repetitivas como la redacción de informes, la transcripción de actas y la síntesis de documentos extensos. Los empleados reportaron una reducción significativa de la carga administrativa, lo que les permitió destinar más tiempo a actividades estratégicas. Sin embargo, también señalaron que en algunos casos la revisión y corrección de las salidas de Copilot demandó tiempo adicional, lo que matizó la percepción de eficiencia total.</p>
                    
                    <h3>Objetivo 2: Examinar de qué manera Copilot promueve o limita la innovación en los procesos de trabajo</h3>
                    <p>La herramienta fue percibida como un facilitador de nuevas formas de trabajo, ya que posibilitó la generación rápida de borradores y propuestas que antes demandaban mucho esfuerzo. Esto abrió espacio para la creatividad en la edición y mejora de textos. No obstante, algunos entrevistados afirmaron que los resultados de Copilot eran <strong>"estándar"</strong> o <strong>"aburridos"</strong>, lo que podría limitar la innovación en contextos que demandan un estilo comunicativo más humano o creativo.</p>
                    
                    <h3>Objetivo 3: Analizar las percepciones de los empleados respecto a la confianza en los resultados generados por Copilot</h3>
                    <p>Las entrevistas evidenciaron una confianza moderada en Copilot: los usuarios reconocieron su utilidad para tareas mecánicas, pero expresaron dudas sobre la precisión y fiabilidad de los textos en contextos más sensibles, como comunicaciones oficiales o documentos jurídicos. Esto refleja que los empleados aún consideran indispensable la supervisión humana para validar la calidad de los resultados.</p>
                    
                    <h3>Objetivo 4: Identificar los cambios en los roles y dinámicas laborales derivados de la introducción de Copilot</h3>
                    <p>Se observó una reconfiguración de los roles en el trabajo diario: Copilot fue asumido por algunos como un <strong>"asistente"</strong> que libera carga administrativa, mientras que otros lo percibieron como un <strong>"coautor"</strong> que colabora en la elaboración de documentos. Sin embargo, también emergió la preocupación por la pérdida de autonomía y competencias profesionales, especialmente entre quienes temen depender demasiado de la herramienta o quedar en desventaja si no se les asigna una licencia.</p>
                    
                    <h3>Objetivo 5: Explorar los desafíos éticos, organizacionales y de gobernanza que emergen con la implementación de IA generativa en el sector público</h3>
                    <p>Los hallazgos indican que los principales desafíos son:</p>
                    <ul>
                        <li><strong>Desigualdad en el acceso,</strong> debido a la distribución limitada de licencias.</li>
                        <li><strong>Privacidad y manejo de datos,</strong> pues algunos empleados expresaron incertidumbre sobre la seguridad de la información procesada.</li>
                        <li><strong>Gobernanza organizacional,</strong> ya que la integración de Copilot requiere lineamientos claros de uso y políticas que garanticen transparencia y equidad.</li>
                        <li><strong>Dependencia tecnológica,</strong> que genera tensiones sobre hasta qué punto se debe confiar en un sistema que no siempre explica sus resultados.</li>
                    </ul>
                </section>
            </div>
        </div>

        <!-- Nueva Sección: Artículo sobre Offline Reinforcement Learning -->
        <div class="content-wrapper">
            <!-- Columna Izquierda: Contenido Completo -->
            <div class="column">
                <section class="section">
                    <h2>Towards Optimizing Human-Centric Objectives in AI-Assisted Decision-Making With Offline Reinforcement Learning</h2>
                    
                    <h3>1. Resumen del artículo</h3>
                    <p>El estudio propone el uso de <strong>aprendizaje por refuerzo offline (Offline RL)</strong> para mejorar la toma de decisiones asistida por IA, no solo en términos de precisión de decisiones, sino también en objetivos humanos como el aprendizaje y la colaboración humano-IA. Se realizaron dos experimentos con 316 y 964 participantes, quienes debían recomendar rutinas de ejercicios a perfiles ficticios, recibiendo distintos tipos de ayuda de la IA (explicaciones, recomendaciones, asistencia bajo demanda). Los resultados mostraron que las políticas optimizadas con RL aumentan la exactitud y, en algunos casos, también el aprendizaje de los participantes.</p>
                    
                    <h3>2. Problemas encontrados</h3>
                    <ul>
                        <li>La mayoría de sistemas de IA para apoyo en decisiones se enfocan únicamente en la precisión, ignorando factores humanos como la motivación, aprendizaje y confianza.</li>
                        <li>Existe el riesgo de sobredependencia de la IA (overreliance), que puede reducir el compromiso cognitivo de las personas.</li>
                        <li>Métodos tradicionales (como recomendaciones fijas) no logran adaptarse a diferentes perfiles cognitivos, especialmente en usuarios con baja o alta "Necesidad de Cognición (NFC)".</li>
                    </ul>
                    
                    <h3>3. Objetivo general y específicos</h3>
                    
                    <h4>Objetivo general:</h4>
                    <p>Optimizar la interacción humano-IA en la toma de decisiones mediante aprendizaje por refuerzo offline, considerando tanto precisión como objetivos humanos (aprendizaje y disfrute de la tarea).</p>
                    
                    <h4>Objetivos específicos:</h4>
                    <ol>
                        <li>Diseñar un sistema de apoyo a la decisión basado en RL capaz de adaptar el tipo de asistencia de IA según el usuario.</li>
                        <li>Evaluar el impacto de las políticas de RL sobre la precisión de las decisiones.</li>
                        <li>Medir si estas políticas mejoran el aprendizaje humano y la percepción de colaboración con la IA.</li>
                        <li>Comparar los resultados con enfoques tradicionales (explicaciones estáticas, recomendaciones fijas, etc.).</li>
                    </ol>
                    
                    <h3>4. Marco teórico</h3>
                    <p><strong>Alan Turing (1950)</strong> planteó si las máquinas podían pensar → <strong>Miller (2021)</strong> retoma esa idea al proponer que la IA no solo recomiende, sino que muestre evidencias para estimular el razonamiento humano.</p>
                    
                    <p><strong>Herbert Simon y Allen Newell (1950-70)</strong> veían la IA como apoyo en la resolución de problemas complejos → <strong>Noti & Chen (2022)</strong> y <strong>Ma et al. (2020)</strong> continúan esa visión al destacar la colaboración humano-IA para tomar mejores decisiones.</p>
                    
                    <p><strong>Marvin Minsky (1960-80)</strong> buscaba imitar procesos cognitivos humanos → <strong>Deci & Ryan (1985)</strong> y <strong>Cacioppo & Petty (1982)</strong> amplían esta perspectiva mostrando cómo la motivación y la necesidad de cognición determinan cómo las personas usan la IA.</p>
                    
                    <p>En conjunto, la disciplina actual de IA centrada en el humano es una evolución directa de los principios fundacionales de la IA: de máquinas que imitan la mente a sistemas que optimizan la interacción humano-IA para mejorar precisión, aprendizaje y motivación.</p>
                    
                    <h3>5. Metodología</h3>
                    <ul>
                        <li><strong>Diseño:</strong> Experimentos controlados online con dos muestras (N=316 y N=964).</li>
                        <li><strong>Tarea:</strong> Recomendación de ejercicios a perfiles ficticios con distintos objetivos (perder peso, flexibilidad, etc.).</li>
                        <li><strong>Condiciones de IA:</strong>
                            <ul>
                                <li>Sin IA</li>
                                <li>Recomendación + explicación</li>
                                <li>Explicación sola</li>
                                <li>Asistencia bajo demanda</li>
                            </ul>
                        </li>
                        <li><strong>Datos:</strong> Se recogieron decisiones de los participantes y se entrenaron políticas de RL con esos datos.</li>
                        <li><strong>Evaluación:</strong> Comparación de políticas optimizadas vs. enfoques tradicionales en términos de:
                            <ul>
                                <li>Precisión en la decisión</li>
                                <li>Aprendizaje (tests posteriores)</li>
                                <li>Disfrute y confianza reportados</li>
                            </ul>
                        </li>
                    </ul>
                    
                    <h3>6. Resultados</h3>
                    
                    <h4>Objetivo general</h4>
                    <p>Optimizar la interacción humano-IA en la toma de decisiones mediante aprendizaje por refuerzo offline, considerando tanto precisión como objetivos humanos (aprendizaje y disfrute).</p>
                    <p><strong>✅ Resultado:</strong> Sí se logró en parte. El RL offline mejoró la precisión y generó políticas más adaptativas. Sin embargo, optimizar el aprendizaje humano fue más difícil: se logró solo en ciertos grupos (los de baja NFC).</p>
                    
                    <h4>📌 Objetivo específico 1:</h4>
                    <p>Diseñar un sistema de apoyo a la decisión basado en RL capaz de adaptar el tipo de asistencia de IA según el usuario.</p>
                    <p><strong>✅ Resultado:</strong> Se desarrolló un sistema con 4 tipos de ayuda (sin IA, recomendación+explicación, solo explicación, bajo demanda) y RL eligió la mejor según contexto y perfil cognitivo.</p>
                    
                    <h4>📌 Objetivo específico 2:</h4>
                    <p>Evaluar el impacto de las políticas de RL sobre la precisión de las decisiones.</p>
                    <p><strong>✅ Resultado:</strong> Las políticas optimizadas con RL superaron significativamente a los métodos tradicionales (ej. recomendaciones fijas) en exactitud.</p>
                    
                    <h5>🔹 ¿Qué son "políticas" en RL?</h5>
                    <p>Una política (policy) en RL es la estrategia que sigue el agente para decidir qué acción tomar en cada situación.</p>
                    <p>En este artículo, la "acción" es qué tipo de ayuda ofrecer al usuario durante la tarea de toma de decisiones.</p>
                    
                    <p><strong>Ejemplos de acciones que forman parte de la política:</strong></p>
                    <ul>
                        <li>Dar una recomendación con explicación.</li>
                        <li>Dar solo una explicación.</li>
                        <li>Dar ayuda bajo demanda.</li>
                        <li>Dar ninguna ayuda.</li>
                    </ul>
                    
                    <p>La política aprendida le dice al sistema en qué momento y a qué tipo de usuario conviene aplicar cada forma de ayuda.</p>
                    
                    <h5>🔹 ¿Qué se hizo en el experimento?</h5>
                    <ol>
                        <li>Primero recolectaron datos de decisiones humanas bajo distintos tipos de ayuda.</li>
                        <li>Con esos datos, entrenaron un modelo de RL offline, que buscó la política óptima: es decir, la combinación de ayudas que maximizaba la precisión de las decisiones.</li>
                        <li>Luego probaron esa política optimizada con nuevos participantes para ver si funcionaba mejor que los métodos tradicionales (ejemplo: siempre dar explicación fija).</li>
                    </ol>
                    
                    <h5>🔹 ¿Cómo se logró el resultado?</h5>
                    <p><strong>Resultado obtenido:</strong> las políticas optimizadas con RL lograron mayor precisión en la toma de decisiones que las políticas tradicionales (ejemplo: siempre dar recomendación o siempre dar explicación).</p>
                    <p>Es decir, la IA aprendió que no hay una sola forma universal de ayudar, sino que la mejor estrategia es adaptar el tipo de ayuda a cada contexto y perfil cognitivo del usuario.</p>
                    
                    <h4>📌 Objetivo específico 3:</h4>
                    <p>Medir si estas políticas mejoran el aprendizaje humano.</p>
                    <p><strong>⚠️ Resultado parcial:</strong> El aprendizaje mejoró en personas con baja necesidad de cognición (NFC), pero no en las de alta NFC. Es más complejo optimizar aprendizaje que precisión.</p>
                    
                    <h4>📌 Objetivo específico 4:</h4>
                    <p>Comparar los resultados con enfoques tradicionales.</p>
                    <p><strong>✅ Resultado:</strong> El RL fue mejor que los métodos clásicos en precisión. En aprendizaje, el RL solo superó en algunos casos, mostrando que aún hay limitaciones.</p>
                    
                    <h3>7. Implicaciones para la Simbiosis Humano-IA</h3>
                    <p>Este estudio refuerza la importancia de considerar <strong>objetivos humanos</strong> más allá de la precisión algorítmica. El aprendizaje por refuerzo offline demuestra que es posible optimizar tanto la eficiencia como el desarrollo cognitivo humano, aunque con limitaciones según el perfil cognitivo del usuario.</p>
                    
                    <p>La investigación conecta directamente con los principios de <strong>delegación bidireccional</strong> y <strong>recalibración de agencia</strong> discutidos en el marco teórico principal, mostrando cómo la IA puede adaptarse dinámicamente a las necesidades humanas específicas, creando una verdadera simbiosis cognitiva.</p>
                </section>
            </div>

            <!-- Columna Derecha: Resumen -->
            <div class="column">
                <section class="section">
                    <h2>Resumen Ejecutivo</h2>
                    
                    <h3>1. Resumen</h3>
                    <p><strong>Offline RL</strong> para optimizar decisiones humano-IA. 2 experimentos (316 y 964 participantes) con recomendaciones de ejercicios. Resultado: mayor exactitud y aprendizaje en algunos casos.</p>
                    
                    <h3>2. Problemas</h3>
                    <ul>
                        <li>Sistemas IA solo enfocados en precisión</li>
                        <li>Riesgo de sobredependencia (overreliance)</li>
                        <li>Métodos tradicionales no se adaptan a perfiles cognitivos</li>
                    </ul>
                    
                    <h3>3. Objetivos</h3>
                    <p><strong>General:</strong> Optimizar interacción humano-IA con RL offline.</p>
                    <p><strong>Específicos:</strong></p>
                    <ol>
                        <li>Sistema RL adaptativo</li>
                        <li>Evaluar impacto en precisión</li>
                        <li>Medir aprendizaje humano</li>
                        <li>Comparar con métodos tradicionales</li>
                    </ol>
                    
                    <h3>4. Marco Teórico</h3>
                    <p><strong>Turing → Miller:</strong> IA que estimula razonamiento humano</p>
                    <p><strong>Simon & Newell → Noti & Chen:</strong> Colaboración humano-IA</p>
                    <p><strong>Minsky → Deci & Ryan:</strong> Motivación y cognición en uso de IA</p>
                    
                    <h3>5. Metodología</h3>
                    <ul>
                        <li>Experimentos online (N=316, N=964)</li>
                        <li>Tarea: recomendación de ejercicios</li>
                        <li>4 condiciones de IA</li>
                        <li>Políticas RL vs. tradicionales</li>
                    </ul>
                    
                    <h3>6. Resultados</h3>
                    <p><strong>✅ Precisión:</strong> RL superó métodos tradicionales</p>
                    <p><strong>⚠️ Aprendizaje:</strong> Mejoró solo en baja NFC</p>
                    <p><strong>✅ Adaptabilidad:</strong> Sistema con 4 tipos de ayuda</p>
                    <p><strong>✅ Comparación:</strong> RL mejor en precisión, limitado en aprendizaje</p>
                    
                    <h3>7. Implicaciones</h3>
                    <p>Refuerza importancia de <strong>objetivos humanos</strong> más allá de precisión algorítmica. Conecta con <strong>delegación bidireccional</strong> y <strong>recalibración de agencia</strong> para crear simbiosis cognitiva.</p>
                </section>
            </div>
        </div>

        <footer class="footer">
            <p>Estudio de caso: Municipio Sueco | Metodología Gioia | Análisis Cualitativo | Offline RL Research</p>
        </footer>
    </div>
</body>
</html>
