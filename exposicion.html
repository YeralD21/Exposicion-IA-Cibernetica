<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Simbiosis Humano-IA - Exposición Académica</title>
    <link rel="stylesheet" href="exposicion.css">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
</head>
<body>
    <div class="container">
        <header class="main-header">
            <h1>Simbiosis humano-IA</h1>
            <h2>Explorando la delegación y la recalibración constante de la agencia</h2>
            <h3>A través de IA generativa</h3>
        </header>

        <div class="content-wrapper">
            <div class="column">
                <section class="section">
                    <h2>Resumen</h2>
                    <p>Este estudio examina la implementación de <strong>inteligencia artificial generativa</strong> en el sector público, aplicando un enfoque de <strong>pensamiento sistémico</strong> para analizar los procesos de delegación dinámica y recalibración de agencia entre humanos y máquinas. La investigación se fundamenta en el <strong>modelado</strong> de sistemas híbridos y la <strong>simulación</strong> de escenarios de colaboración humano-IA.</p>
                    
                    <p>Mediante un <strong>estudio de caso cualitativo</strong> en un municipio sueco, se analiza la colaboración simbiótica que emerge cuando los sistemas de IA generativa se integran en entornos organizacionales complejos. El enfoque metodológico combina <strong>análisis cualitativo</strong> con técnicas de <strong>optimización</strong> de procesos, utilizando la metodología Gioia para la codificación y análisis de datos.</p>
                    
                    <p>El estudio propone un <strong>marco conceptual</strong> basado en <strong>delegación bidireccional</strong> y <strong>recalibración de agencia</strong>, posicionando la IA generativa como una <strong>herramienta de apoyo a la toma de decisiones</strong> que complementa las capacidades humanas. Los resultados evidencian la evolución hacia sistemas híbridos que optimizan tanto la eficiencia algorítmica como la supervisión humana, estableciendo un modelo de <strong>sistemas blandos</strong> adaptativos para la gobernanza pública.</p>
                </section>

                <section class="section">
                    <h2>Planteamiento del Problema y Objetivos</h2>
                    <h3>Problema Central</h3>
                    <p>La distribución de agencia entre humanos y máquinas presenta tensiones fundamentales entre la eficiencia algorítmica y la necesidad de supervisión humana. Esta tensión se intensifica en el sector público, donde las decisiones tienen implicaciones directas en la vida ciudadana.</p>
                    
                    <h3>Justificación Contextual</h3>
                    <p>La modernización del sector público mediante IA genera dilemas éticos complejos que requieren marcos conceptuales robustos para guiar la implementación responsable de estas tecnologías.</p>
                    
                    <h3>Objetivos de Investigación</h3>
                    <ul>
                        <li>Explorar los mecanismos de delegación humano-IA en contextos organizacionales</li>
                        <li>Analizar los procesos de recalibración de agencia en sistemas híbridos</li>
                        <li>Proponer un marco conceptual para la simbiosis humano-IA</li>
                    </ul>
                </section>

                <section class="section">
                    <h2>Marco Teórico</h2>
                    <h3>Fundamentos de la Inteligencia Artificial</h3>
                    <p>La Inteligencia Artificial (IA) no nació de un solo científico, sino de un grupo de pensadores y disciplinas que se unieron en los años 40–50 y se consolidaron como campo formal en 1956. Desde entonces, la IA se ha definido como una disciplina de la informática encargada de desarrollar sistemas y programas capaces de realizar tareas que normalmente requieren inteligencia humana, como el razonamiento, la toma de decisiones, el aprendizaje y la adaptación.</p>
                    
                    <p>En el presente estudio, se aborda la IA desde una perspectiva cognitiva y simbiótica, enfocada en su capacidad para colaborar con humanos en entornos complejos como el sector público.</p>
                    
                    <h3>Herbert Simon y la Racionalidad Limitada</h3>
                    <p>Esta visión se articula con los aportes de <strong>Herbert Simon</strong>, citado en el documento base de esta investigación, quien fue pionero en el estudio de la toma de decisiones administrativas y en el desarrollo de modelos computacionales que simulan procesos cognitivos humanos. Su teoría de la <strong>racionalidad limitada</strong> no solo transformó la gestión pública, sino que también sentó las bases para el diseño de sistemas inteligentes capaces de colaborar con humanos en entornos inciertos.</p>
                    
                    <p>En este marco, la IA no se concibe como sustituto del juicio humano, sino como <strong>amplificador cognitivo</strong>, capaz de extender la capacidad de análisis, síntesis y decisión en contextos organizacionales.</p>
                    
                    <h3>Modelos de Delegación en Sistemas Humano-IA</h3>
                    <p>Para comprender la dinámica de colaboración entre humanos y sistemas de inteligencia artificial, es fundamental analizar los modelos de delegación que estructuran dicha interacción. Diversos estudios han identificado tres tipos principales de delegación: de humano a IA, de IA a humano, y bidireccional. Estos modelos permiten mapear cómo se distribuyen las responsabilidades en sistemas inteligentes y cómo se recalibra la agencia en función del contexto, la competencia y el aprendizaje mutuo.</p>
                    
                    <div class="image-container">
                        <h4>Tabla 2. Tipos de delegación en sistemas humano-IA: definición y referencias clave</h4>
                        <img src="qwe123.png" alt="Tabla de tipos de delegación en sistemas humano-IA" class="methodology-image">
                    </div>
                    
                    <h3>Análisis de los Modelos de Delegación</h3>
                    <p>La tabla sintetiza los tres modelos de delegación más relevantes en el campo de la interacción humano-IA.</p>
                    
                    <ul>
                        <li>En la <strong>delegación Humano-IA</strong>, el humano asigna tareas al sistema, manteniendo supervisión parcial.</li>
                        <li>En la <strong>delegación IA-Humano</strong>, el sistema transfiere decisiones al humano, evaluando su competencia.</li>
                        <li>En la <strong>delegación bidireccional</strong>, ambos actores colaboran activamente, ajustando sus roles según el flujo de trabajo.</li>
                    </ul>
                    
                    <p>Estos modelos, respaldados por autores como Shrestha, Fügener, Carroll y Lebovitz, constituyen la base conceptual para entender la <strong>simbiosis humano-IA</strong>. En particular, la delegación bidireccional representa el ideal de colaboración adaptativa, donde la agencia se distribuye dinámicamente y se retroalimenta en tiempo real. Este marco teórico se conecta directamente con los principios de la <strong>cibernética organizacional</strong>, al considerar la interacción como un sistema auto-regulado, sensible al entorno y capaz de evolucionar.</p>
                    
                    <h3>Recalibración de Agencia</h3>
                    <p>Basada en la teoría de la racionalidad limitada, la recalibración permite ajustes dinámicos en la distribución de responsabilidades según el contexto y el desempeño del sistema.</p>
                    
                    <h3>Simbiosis Humano-IA</h3>
                    <p>Inspirada en la cibernética organizacional, esta relación mutuamente beneficiosa optimiza las capacidades tanto humanas como artificiales, creando sinergias que superan las limitaciones individuales.</p>
                </section>
            </div>

            <div class="column">
                <section class="section">
                    <h2>Gobernanza Ética</h2>
                    <p>Los principios fundamentales incluyen la <strong>transparencia</strong> en los procesos algorítmicos, la <strong>responsabilidad compartida</strong> entre humanos y sistemas, y la <strong>equidad organizacional</strong> en la distribución de beneficios y riesgos.</p>
                    
                    <h3>Conexiones Conceptuales</h3>
                    <ul>
                        <li>Automatización híbrida: combinación de control humano y automático</li>
                        <li>Ingeniería de prompts: optimización de interacciones humano-IA</li>
                        <li>Ética algorítmica: marcos para decisiones justas y transparentes</li>
                    </ul>
                </section>

                <section class="section">
                    <h2>Metodología</h2>
                    
                    <h3>Enfoque de Investigación</h3>
                    <p>La presente investigación adopta un <strong>enfoque cualitativo</strong> para analizar la interacción entre humanos y sistemas de inteligencia artificial generativa en el sector público. Se busca comprender cómo se distribuyen las responsabilidades entre ambos actores y cómo se ajusta la agencia humana en función del desempeño algorítmico.</p>
                    
                    <h3>Diseño Metodológico</h3>
                    <p>Se utilizó un <strong>estudio de caso</strong> en un municipio sueco que implementó Microsoft Copilot como herramienta de IA generativa en tareas administrativas. La recolección de datos se realizó mediante <strong>entrevistas semiestructuradas</strong> a empleados públicos, enfocadas en sus experiencias de delegación, confianza y colaboración con la IA.</p>
                    
                    <p>Para el análisis, se aplicó la <strong>metodología Gioia</strong>, que permite construir teoría a partir de datos empíricos mediante codificación abierta, axial y agregada. Este enfoque facilitó la identificación de conceptos de primer orden (acciones observadas), categorías de segundo orden (interpretaciones organizacionales), y dimensiones agregadas (constructos teóricos).</p>
                    
                    <h3>Conexión con Cibernética Organizacional</h3>
                    <p>El comportamiento observado en la interacción humano-IA refleja principios de la <strong>cibernética organizacional</strong>, especialmente en lo que respecta a la <strong>retroalimentación continua</strong> y el <strong>control adaptativo</strong>. Los participantes ajustaban sus decisiones en función de las respuestas de la IA, y la IA, a su vez, modificaba sus recomendaciones según el contexto y el historial de uso. Este ciclo de ajuste dinámico constituye un sistema auto-regulado, alineado con los postulados de <strong>Norbert Wiener</strong> sobre control y comunicación en sistemas inteligentes.</p>
                    
                    <h3>Análisis Inductivo y Mapa Conceptual</h3>
                    <p>Como parte del análisis cualitativo, se utilizó un enfoque inductivo para identificar patrones emergentes en la interacción humano-IA dentro el sector público. Para ello, se construyó un mapa conceptual que sintetiza las dimensiones clave observadas durante el estudio de caso. Este diagrama representa las categorías temáticas que surgieron del proceso de codificación, alineadas con la metodología Gioia.</p>
                    
                    <div class="image-container">
                        <h4>Dimensiones emergentes en la interacción humano-IA</h4>
                        <img src="asdf.png" alt="Mapa conceptual de dimensiones emergentes en la interacción humano-IA" class="methodology-image">
                    </div>
                    
                    <h3>Proceso de Codificación Gioia</h3>
                    <p>Siguiendo el enfoque de Gioia, se realizó una codificación abierta de las entrevistas semiestructuradas, lo que permitió identificar conceptos de primer orden relacionados con el uso de IA generativa en tareas administrativas, toma de decisiones, colaboración y desarrollo profesional. Estos conceptos fueron agrupados en categorías de segundo orden, como transformación de la fuerza laboral, gobernanza ética, confianza en IA, y ecosistemas híbridos de decisión. Finalmente, se consolidaron en dimensiones agregadas que estructuran el modelo conceptual propuesto.</p>
                    
                    <p>El diagrama refleja esta progresión inductiva, mostrando cómo la adopción de IA generativa impacta múltiples niveles organizacionales: desde la automatización de tareas hasta la redefinición de roles humanos, pasando por la necesidad de estrategias sostenibles y protocolos éticos. Cada categoría representa un nodo de análisis que contribuye a entender la simbiosis humano-IA como un sistema adaptativo, distribuido y en constante recalibración.</p>
                    
                    <h3>Dimensiones Emergentes</h3>
                    <ul>
                        <li>Transformación laboral y nuevas competencias</li>
                        <li>Gobernanza ética en sistemas híbridos</li>
                        <li>Ecosistemas híbridos de colaboración</li>
                        <li>Construcción de confianza humano-IA</li>
                        <li>Estrategias para implementación sostenible</li>
                    </ul>
                </section>

                <section class="section">
                    <h2>Resultados y Discusión</h2>
                    
                    <h3>Resultados en Relación con los Objetivos</h3>
                    
                    <h4>1. Delegación Humano-IA en Entornos Reales</h4>
                    <p>El estudio confirmó la existencia de <strong>patrones diferenciados de delegación</strong> según la naturaleza de las tareas. Las tareas rutinarias (procesamiento de documentos, análisis de datos básicos) se delegaron efectivamente a la IA, mientras que las decisiones estratégicas y casos sensibles mantuvieron supervisión humana directa. Esta diferenciación responde directamente al primer objetivo, evidenciando que la delegación no es binaria sino <strong>contextual y adaptativa</strong>.</p>
                    
                    <h4>2. Recalibración de Agencia en Función de la IA</h4>
                    <p>Se observó un proceso de <strong>recalibración continua</strong> que se ajustaba dinámicamente según tres factores clave: (a) el desempeño medible de la IA en tareas específicas, (b) la complejidad del contexto organizacional, y (c) el nivel de confianza desarrollado entre humanos y sistemas. Los trabajadores reportaron una evolución desde la supervisión constante hacia una <strong>colaboración más fluida</strong>, validando el segundo objetivo de investigación.</p>
                    
                    <h4>3. Validación del Marco Conceptual de Colaboración Simbiótica</h4>
                    <p>El marco propuesto se validó parcialmente a través de la emergencia de <strong>nuevas competencias híbridas</strong>. Los trabajadores desarrollaron habilidades en ingeniería de prompts, interpretación de resultados algorítmicos, y ética digital, transformando su rol de operadores a <strong>colaboradores estratégicos</strong>. Esta evolución confirma la viabilidad del modelo simbiótico propuesto.</p>
                    
                    <h3>Respuesta al Problema Central</h3>
                    <p>Los resultados abordan directamente la <strong>tensión entre eficiencia algorítmica y supervisión humana</strong> en el sector público. Se identificó que esta tensión se resuelve mediante un <strong>modelo híbrido</strong> donde la eficiencia algorítmica se optimiza en tareas rutinarias, mientras que la supervisión humana se mantiene en decisiones de alto impacto. La clave está en la <strong>transparencia de los procesos</strong> y la capacidad de los humanos para interpretar y validar las decisiones algorítmicas.</p>
                    
                    <h3>Discusión e Interpretación</h3>
                    
                    <h4>Confirmaciones</h4>
                    <p>Se confirma que la <strong>simbiosis humano-IA es viable</strong> en entornos organizacionales complejos cuando se implementa con marcos éticos robustos. La delegación dinámica emerge como un mecanismo natural de adaptación, no como una imposición tecnológica.</p>
                    
                    <h4>Matizaciones</h4>
                    <p>Sin embargo, la simbiosis requiere <strong>tiempo de adaptación</strong> y desarrollo de competencias específicas. No es un proceso automático, sino que demanda inversión en formación y cambio cultural organizacional.</p>
                    
                    <h4>Propuestas de Mejora</h4>
                    <ul>
                        <li>Implementar <strong>protocolos de transparencia algorítmica</strong> que permitan a los humanos comprender el razonamiento de la IA</li>
                        <li>Desarrollar <strong>métricas de confianza</strong> que guíen los procesos de recalibración</li>
                        <li>Crear <strong>marcos de gobernanza ética</strong> específicos para el sector público</li>
                    </ul>
                    
                    <h3>Limitaciones y Riesgos Identificados</h3>
                    <p><strong>Limitaciones del estudio:</strong> El análisis se limitó a un municipio sueco, lo que puede limitar la generalización a otros contextos culturales y organizacionales. Además, el período de observación fue de 18 meses, insuficiente para evaluar efectos a largo plazo.</p>
                    
                    <p><strong>Riesgos emergentes:</strong> Se identificaron tres riesgos críticos: (1) <strong>desigualdad de acceso</strong> a herramientas de IA entre diferentes niveles organizacionales, (2) <strong>opacidad en procesos algorítmicos</strong> que puede erosionar la confianza, y (3) <strong>falta de protocolos</strong> para supervisión ética en casos de conflicto entre decisiones humanas y algorítmicas.</p>
                    
                    <h3>Validación del Marco Conceptual</h3>
                    <p>El marco conceptual de colaboración simbiótica se <strong>valida parcialmente</strong> a través de los resultados obtenidos. La emergencia de competencias híbridas y la evolución hacia roles colaborativos confirman la viabilidad del modelo. Sin embargo, se requiere <strong>refinamiento en los mecanismos de gobernanza</strong> para abordar los riesgos identificados y asegurar la sostenibilidad del modelo a largo plazo.</p>
                </section>
            </div>
        </div>

        <footer class="footer">
            <p>Estudio de caso: Municipio Sueco | Metodología Gioia | Análisis Cualitativo</p>
        </footer>
    </div>
</body>
</html>
