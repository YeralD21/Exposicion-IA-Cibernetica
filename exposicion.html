<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Simbiosis Humano-IA - Exposición Académica</title>
    <link rel="stylesheet" href="exposicion.css">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
</head>a
<body>
    <div class="container">
        <header class="main-header">
            <h1>Simbiosis humano-IA</h1>
            <h2>Explorando la delegación y la recalibración constante de la agencia</h2>
            <h3>A través de IA generativa</h3>
        </header>

        <div class="content-wrapper">
            <div class="column">
                <section class="section">
                    <h2>Resumen</h2>
                    <p>Este estudio examina la implementación de <strong>inteligencia artificial generativa</strong> en el sector público, aplicando un enfoque de <strong>pensamiento sistémico</strong> para analizar los procesos de delegación dinámica y recalibración de agencia entre humanos y máquinas. La investigación se fundamenta en el <strong>modelado</strong> de sistemas híbridos y la <strong>simulación</strong> de escenarios de colaboración humano-IA.</p>
                    
                    <p>Mediante un <strong>estudio de caso cualitativo</strong> en un municipio sueco, se analiza la colaboración simbiótica que emerge cuando los sistemas de IA generativa se integran en entornos organizacionales complejos. El enfoque metodológico combina <strong>análisis cualitativo</strong> con técnicas de <strong>optimización</strong> de procesos, utilizando la metodología Gioia para la codificación y análisis de datos.</p>
                    
                    <p>El estudio propone un <strong>marco conceptual</strong> basado en <strong>delegación bidireccional</strong> y <strong>recalibración de agencia</strong>, posicionando la IA generativa como una <strong>herramienta de apoyo a la toma de decisiones</strong> que complementa las capacidades humanas. Los resultados evidencian la evolución hacia sistemas híbridos que optimizan tanto la eficiencia algorítmica como la supervisión humana, estableciendo un modelo de <strong>sistemas blandos</strong> adaptativos para la gobernanza pública.</p>
                </section>

                <section class="section">
                    <h2>Planteamiento del Problema y Objetivos</h2>
                    <h3>Problema Central</h3>
                    <p>La distribución de agencia entre humanos y máquinas presenta tensiones fundamentales entre la eficiencia algorítmica y la necesidad de supervisión humana. Esta tensión se intensifica en el sector público, donde las decisiones tienen implicaciones directas en la vida ciudadana.</p>
                    
                    <h3>Justificación Contextual</h3>
                    <p>La modernización del sector público mediante IA genera dilemas éticos complejos que requieren marcos conceptuales robustos para guiar la implementación responsable de estas tecnologías.</p>
                    
                    <h3>Objetivos de Investigación</h3>
                    <ul>
                        <li>Explorar los mecanismos de delegación humano-IA en contextos organizacionales</li>
                        <li>Analizar los procesos de recalibración de agencia en sistemas híbridos</li>
                        <li>Proponer un marco conceptual para la simbiosis humano-IA</li>
                    </ul>
                </section>

                <section class="section">
                    <h2>Marco Teórico</h2>
                    <h3>Fundamentos de la Inteligencia Artificial</h3>
                    <p>La Inteligencia Artificial (IA) no nació de un solo científico, sino de un grupo de pensadores y disciplinas que se unieron en los años 40–50 y se consolidaron como campo formal en 1956. Desde entonces, la IA se ha definido como una disciplina de la informática encargada de desarrollar sistemas y programas capaces de realizar tareas que normalmente requieren inteligencia humana, como el razonamiento, la toma de decisiones, el aprendizaje y la adaptación.</p>
                    
                    <p>En el presente estudio, se aborda la IA desde una perspectiva cognitiva y simbiótica, enfocada en su capacidad para colaborar con humanos en entornos complejos como el sector público.</p>
                    
                    <h3>Herbert Simon y la Racionalidad Limitada</h3>
                    <p>Esta visión se articula con los aportes de <strong>Herbert Simon</strong>, citado en el documento base de esta investigación, quien fue pionero en el estudio de la toma de decisiones administrativas y en el desarrollo de modelos computacionales que simulan procesos cognitivos humanos. Su teoría de la <strong>racionalidad limitada</strong> no solo transformó la gestión pública, sino que también sentó las bases para el diseño de sistemas inteligentes capaces de colaborar con humanos en entornos inciertos.</p>
                    
                    <p>En este marco, la IA no se concibe como sustituto del juicio humano, sino como <strong>amplificador cognitivo</strong>, capaz de extender la capacidad de análisis, síntesis y decisión en contextos organizacionales.</p>
                    
                    <h3>Modelos de Delegación en Sistemas Humano-IA</h3>
                    <p>Para comprender la dinámica de colaboración entre humanos y sistemas de inteligencia artificial, es fundamental analizar los modelos de delegación que estructuran dicha interacción. Diversos estudios han identificado tres tipos principales de delegación: de humano a IA, de IA a humano, y bidireccional. Estos modelos permiten mapear cómo se distribuyen las responsabilidades en sistemas inteligentes y cómo se recalibra la agencia en función del contexto, la competencia y el aprendizaje mutuo.</p>
                    
                    <div class="image-container">
                        <h4>Tabla 2. Tipos de delegación en sistemas humano-IA: definición y referencias clave</h4>
                        <img src="qwe123.png" alt="Tabla de tipos de delegación en sistemas humano-IA" class="methodology-image">
                    </div>
                    
                    <h3>Análisis de los Modelos de Delegación</h3>
                    <p>La tabla sintetiza los tres modelos de delegación más relevantes en el campo de la interacción humano-IA.</p>
                    
                    <ul>
                        <li>En la <strong>delegación Humano-IA</strong>, el humano asigna tareas al sistema, manteniendo supervisión parcial.</li>
                        <li>En la <strong>delegación IA-Humano</strong>, el sistema transfiere decisiones al humano, evaluando su competencia.</li>
                        <li>En la <strong>delegación bidireccional</strong>, ambos actores colaboran activamente, ajustando sus roles según el flujo de trabajo.</li>
                    </ul>
                    
                    <p>Estos modelos, respaldados por autores como Shrestha, Fügener, Carroll y Lebovitz, constituyen la base conceptual para entender la <strong>simbiosis humano-IA</strong>. En particular, la delegación bidireccional representa el ideal de colaboración adaptativa, donde la agencia se distribuye dinámicamente y se retroalimenta en tiempo real. Este marco teórico se conecta directamente con los principios de la <strong>cibernética organizacional</strong>, al considerar la interacción como un sistema auto-regulado, sensible al entorno y capaz de evolucionar.</p>
                    
                    <h3>Recalibración de Agencia</h3>
                    <p>Basada en la teoría de la racionalidad limitada, la recalibración permite ajustes dinámicos en la distribución de responsabilidades según el contexto y el desempeño del sistema.</p>
                    
                    <h3>Simbiosis Humano-IA</h3>
                    <p>Inspirada en la cibernética organizacional, esta relación mutuamente beneficiosa optimiza las capacidades tanto humanas como artificiales, creando sinergias que superan las limitaciones individuales.</p>
                    
                    <h3>Conceptos</h3>
                    <p><strong>Holmström y Carroll (2024)</strong> ilustran aún más este punto de vista al enfatizar la perspectiva de una relación mutuamente interdependiente en lugar de una de exclusión, y al enfatizar los beneficios sinérgicos. La perspectiva tradicional sugiere que la IA es superior a los humanos en el procesamiento del lenguaje y el reconocimiento de patrones <strong>(Shrestha et al., 2019)</strong>.</p>
                    
                    <p>Por lo tanto, en el ámbito médico, por ejemplo, se utilizaron agentes de IA para filtrar alternativas y reducirlas, mientras que el agente humano, es decir, el profesional médico, evaluaba esas opciones y tomaba la decisión final como una forma de aumento participativo <strong>(Lebovitz et al., 2022)</strong>. En consecuencia, el desarrollo de la IA puede considerarse una dinámica dialéctica y mutuamente dependiente entre los humanos y la IA <strong>(Van den Broek et al., 2021; Shrestha et al., 2019)</strong>.</p>
                    
                    <p>Si bien se alaba la capacidad de la IA para analizar grandes volúmenes de datos y reconocer patrones, la contextualización, el razonamiento ético y la reflexividad crítica que proporciona sentido solo se manifiestan en humanos <strong>(Sundberg y Holmström, 2024)</strong>. Este tipo de relación simbiótica es una vía que impulsaría aún más el proceso de aprendizaje, perfeccionando así las habilidades algorítmicas junto con la inteligencia humana <strong>(Van den Broek et al., 2021)</strong>.</p>
                    
                    <p>Por esto <strong>Kaplan & Haenlein</strong> definen la IA como la capacidad de interpretar datos y adaptarse a objetivos específicos, retomando la discusión iniciada por <strong>Alan Turing</strong>, quien planteó la pregunta sobre qué significa realmente considerar a una máquina inteligente mediante su Test de Turing.</p>
                    
                    <p><strong>Brynjolfsson & McAfee</strong> destacan el impacto económico y organizacional de la IA, ampliando la visión de <strong>John McCarthy</strong>, quien acuñó el término Inteligencia Artificial y la presentó como la ciencia de construir máquinas inteligentes.</p>
                    
                    <p>Las ideas de <strong>Marvin Minsky</strong> sobre la mente como proceso computable y sus avances en redes neuronales encuentran eco en los trabajos de <strong>Brynjolfsson, McAfee y Davenport</strong>, quienes analizan cómo el aprendizaje automático transforma la productividad y la toma de decisiones.</p>
                    
                    <p>Los aportes de <strong>Herbert Simon y Allen Newell</strong> en la resolución lógica de problemas se reflejan en las reflexiones de <strong>Davenport y Mittelstadt</strong>, que discuten los límites y riesgos de delegar decisiones a los algoritmos, subrayando la importancia de la transparencia y la rendición de cuentas.</p>
                    
                    <p>La visión de <strong>Norbert Wiener</strong> sobre la cibernética y los sistemas de retroalimentación humano-máquina se prolonga en los estudios de <strong>Kaplan, Haenlein y Mikalef</strong>, quienes analizan la necesidad de confianza, gobernanza y ajuste continuo en los ecosistemas híbridos de colaboración humano-IA.</p>
                </section>
            </div>

            <div class="column">
                <section class="section">
                    <h2>Gobernanza Ética</h2>
                    <p>Los principios fundamentales incluyen la <strong>transparencia</strong> en los procesos algorítmicos, la <strong>responsabilidad compartida</strong> entre humanos y sistemas, y la <strong>equidad organizacional</strong> en la distribución de beneficios y riesgos.</p>
                    
                    <h3>Conexiones Conceptuales</h3>
                    <ul>
                        <li>Automatización híbrida: combinación de control humano y automático</li>
                        <li>Ingeniería de prompts: optimización de interacciones humano-IA</li>
                        <li>Ética algorítmica: marcos para decisiones justas y transparentes</li>
                    </ul>
                </section>

                <section class="section">
                    <h2>Metodología</h2>
                    
                    <h3>1. Metodología de Investigación</h3>
                    
                    <h4>Enfoques</h4>
                    <p>La presente investigación adopta un <strong>enfoque cualitativo</strong> para analizar la interacción entre humanos y sistemas de inteligencia artificial generativa en el sector público. Se busca comprender cómo se distribuyen las responsabilidades entre ambos actores y cómo se ajusta la agencia humana en función del desempeño algorítmico.</p>
                    
                    <p>Se utilizó un <strong>estudio de caso</strong> en un municipio sueco que implementó Microsoft Copilot como herramienta de IA generativa en tareas administrativas. La recolección de datos se realizó mediante <strong>entrevistas semiestructuradas</strong> a empleados públicos, enfocadas en sus experiencias de delegación, confianza y colaboración con la IA.</p>
                    
                    <p>Para el análisis, se aplicó la <strong>metodología Gioia</strong>, que permite construir teoría a partir de datos empíricos mediante codificación abierta, axial y agregada. Este enfoque facilitó la identificación de conceptos de primer orden (acciones observadas), categorías de segundo orden (interpretaciones organizacionales), y dimensiones agregadas (constructos teóricos).</p>
                    
                    <p>El comportamiento observado en la interacción humano-IA refleja principios de la <strong>cibernética organizacional</strong>, especialmente en lo que respecta a la <strong>retroalimentación continua</strong> y el <strong>control adaptativo</strong>. Los participantes ajustaban sus decisiones en función de las respuestas de la IA, y la IA, a su vez, modificaba sus recomendaciones según el contexto y el historial de uso. Este ciclo de ajuste dinámico constituye un sistema auto-regulado, alineado con los postulados de <strong>Norbert Wiener</strong> sobre control y comunicación en sistemas inteligentes.</p>
                    
                    <h3>2. Metodología de Implementación – IA (Características)</h3>
                    
                    <h4>Tipo de IA utilizada</h4>
                    <p><strong>IA generativa</strong> (Microsoft Copilot) basada en modelos de lenguaje de gran escala (LLM), con capacidad de procesar lenguaje natural, redactar documentos y asistir en tareas administrativas.</p>
                    
                    <h4>Características técnicas</h4>
                    <ul>
                        <li><strong>Automatización:</strong> Delegación de tareas repetitivas y de bajo valor cognitivo</li>
                        <li><strong>Aumentación:</strong> Asistencia en toma de decisiones y apoyo en creatividad (redacción de informes, síntesis de datos)</li>
                        <li><strong>Retroalimentación continua:</strong> La herramienta aprende y se ajusta a través del uso</li>
                        <li><strong>Transparencia limitada:</strong> Dependencia de la explicabilidad y confianza en los resultados</li>
                    </ul>
                    
                    <h4>Proceso de integración</h4>
                    <ul>
                        <li><strong>Fase piloto:</strong> Uso experimental en administración municipal</li>
                        <li><strong>Asignación de licencias:</strong> Distribución restringida, generando dinámicas de acceso desigual</li>
                        <li><strong>Pruebas de usabilidad:</strong> Talleres, sesiones de aprendizaje y experimentación</li>
                        <li><strong>Evaluación de desempeño:</strong> Medición de eficiencia, ahorro de tiempo y calidad de tareas</li>
                    </ul>
                    
                    <h4>Consideraciones éticas y factores de éxito</h4>
                    <ul>
                        <li><strong>Privacidad de datos:</strong> Anonimización de información sensible</li>
                        <li><strong>Supervisión humana:</strong> Usuario mantiene responsabilidad en decisiones críticas</li>
                        <li><strong>Capacitación:</strong> Alfabetización digital y prompt engineering</li>
                        <li><strong>Cultura organizacional:</strong> Apertura al cambio tecnológico</li>
                    </ul>
                    
                    <h3>Análisis Inductivo y Mapa Conceptual</h3>
                    <p>Como parte del análisis cualitativo, se utilizó un enfoque inductivo para identificar patrones emergentes en la interacción humano-IA dentro el sector público. Para ello, se construyó un mapa conceptual que sintetiza las dimensiones clave observadas durante el estudio de caso. Este diagrama representa las categorías temáticas que surgieron del proceso de codificación, alineadas con la metodología Gioia.</p>
                    
                    <div class="image-container">
                        <h4>Dimensiones emergentes en la interacción humano-IA</h4>
                        <img src="asdf.png" alt="Mapa conceptual de dimensiones emergentes en la interacción humano-IA" class="methodology-image">
                    </div>
                    
                    <h3>Análisis de Datos y Metodología Gioia</h3>
                    <p>Siguiendo los pasos sistemático-inductivos tradicionales de la metodología Gioia, nuestro análisis combina una profunda interacción con los informantes en un enfoque iterativo de construcción teórica <strong>(Gioia et al., 2013)</strong>. Parte del supuesto de que los participantes son "agentes con conocimiento" capaces de expresar con elocuencia sus experiencias y la construcción de significado.</p>
                    
                    <p>Las entrevistas semiestructuradas se realizaron en un municipio sueco para comprender cómo los empleados integran e interpretan Microsoft Copilot en sus operaciones diarias. Esta atención a las palabras de los informantes mejoró nuestra codificación in vivo y nos permitió capturar las expresiones de los participantes sin imponer preconcepciones teóricas prematuras <strong>(Gioia et al., 2013; Corley y Gioia, 2004)</strong>.</p>
                    
                    <h4>Ejemplo Práctico de Codificación</h4>
                    <p>Un hallazgo revelador emergió durante la codificación: los empleados se referían a Copilot de manera variable según su función percibida. En ocasiones lo consideraban una <strong>"secretaria de oficina más eficiente"</strong> para tareas rutinarias, mientras que en otras lo describían como <strong>"profesor o coautor"</strong> para funciones creativas. Esta variabilidad en las etiquetas sugiere que Copilot opera bajo múltiples roles simultáneos, desde resolver tareas prácticas cotidianas hasta facilitar colaboraciones más amplias.</p>
                    
                    <h3>Proceso de Codificación Gioia</h3>
                    <p>Tras realizar la codificación in vivo, desarrollamos conjuntos preliminares de códigos de primer orden. Para mejorar la credibilidad y el rigor del análisis, cada autor analizó de forma independiente la codificación in vivo <strong>(Denzin, 1978; Patton, 1999)</strong>. Uno generó 105 códigos a partir de 641 citas, mientras que el otro 176 códigos a partir de 460. Estos conjuntos se triangularon mediante comparaciones iterativas.</p>
                    
                    <p>Los temas de segundo orden se presentan como ideas estrechamente situadas y conceptualmente relacionadas, representativas de ideas subyacentes más abstractas. Se siguió la guía de <strong>Pratt (2009)</strong> sobre las "citas de poder", utilizadas para mostrar datos en lugar de simplemente describirlos, creando así una cadena de evidencia que destaca cómo las voces de los informantes informan críticamente nuestras perspectivas teóricas.</p>
                    
                    <p>El proceso culminó en la derivación de 15 conceptos de primer orden, sus correspondientes temas de segundo orden y cinco dimensiones agregadas, generando así un resultado preliminar del análisis de Gioia que estructura el modelo conceptual propuesto.</p>
                    
                    <p>El diagrama refleja esta progresión inductiva, mostrando cómo la adopción de IA generativa impacta múltiples niveles organizacionales: desde la automatización de tareas hasta la redefinición de roles humanos, pasando por la necesidad de estrategias sostenibles y protocolos éticos. Cada categoría representa un nodo de análisis que contribuye a entender la simbiosis humano-IA como un sistema adaptativo, distribuido y en constante recalibración.</p>
                    
                    <h3>Dimensiones Emergentes</h3>
                    <ul>
                        <li>Transformación laboral y nuevas competencias</li>
                        <li>Gobernanza ética en sistemas híbridos</li>
                        <li>Ecosistemas híbridos de colaboración</li>
                        <li>Construcción de confianza humano-IA</li>
                        <li>Estrategias para implementación sostenible</li>
                    </ul>
                </section>

                <section class="section">
                    <h2>Resultados y Discusión</h2>
                    
                    <h3>Resultados en Relación con los Objetivos</h3>
                    
                    <h4>1. Delegación Humano-IA en Entornos Reales</h4>
                    <p>El estudio confirmó la existencia de <strong>patrones diferenciados de delegación</strong> según la naturaleza de las tareas. Las tareas rutinarias (procesamiento de documentos, análisis de datos básicos) se delegaron efectivamente a la IA, mientras que las decisiones estratégicas y casos sensibles mantuvieron supervisión humana directa. Esta diferenciación responde directamente al primer objetivo, evidenciando que la delegación no es binaria sino <strong>contextual y adaptativa</strong>.</p>
                    
                    <h4>2. Recalibración de Agencia en Función de la IA</h4>
                    <p>Se observó un proceso de <strong>recalibración continua</strong> que se ajustaba dinámicamente según tres factores clave: (a) el desempeño medible de la IA en tareas específicas, (b) la complejidad del contexto organizacional, y (c) el nivel de confianza desarrollado entre humanos y sistemas. Los trabajadores reportaron una evolución desde la supervisión constante hacia una <strong>colaboración más fluida</strong>, validando el segundo objetivo de investigación.</p>
                    
                    <h4>3. Validación del Marco Conceptual de Colaboración Simbiótica</h4>
                    <p>El marco propuesto se validó parcialmente a través de la emergencia de <strong>nuevas competencias híbridas</strong>. Los trabajadores desarrollaron habilidades en ingeniería de prompts, interpretación de resultados algorítmicos, y ética digital, transformando su rol de operadores a <strong>colaboradores estratégicos</strong>. Esta evolución confirma la viabilidad del modelo simbiótico propuesto.</p>
                    
                    <h3>Respuesta al Problema Central</h3>
                    <p>Los resultados abordan directamente la <strong>tensión entre eficiencia algorítmica y supervisión humana</strong> en el sector público. Se identificó que esta tensión se resuelve mediante un <strong>modelo híbrido</strong> donde la eficiencia algorítmica se optimiza en tareas rutinarias, mientras que la supervisión humana se mantiene en decisiones de alto impacto. La clave está en la <strong>transparencia de los procesos</strong> y la capacidad de los humanos para interpretar y validar las decisiones algorítmicas.</p>
                    
                    <h3>Discusión e Interpretación</h3>
                    
                    <h4>Confirmaciones</h4>
                    <p>Se confirma que la <strong>simbiosis humano-IA es viable</strong> en entornos organizacionales complejos cuando se implementa con marcos éticos robustos. La delegación dinámica emerge como un mecanismo natural de adaptación, no como una imposición tecnológica.</p>
                    
                    <h4>Matizaciones</h4>
                    <p>Sin embargo, la simbiosis requiere <strong>tiempo de adaptación</strong> y desarrollo de competencias específicas. No es un proceso automático, sino que demanda inversión en formación y cambio cultural organizacional.</p>
                    
                    <h4>Propuestas de Mejora</h4>
                    <ul>
                        <li>Implementar <strong>protocolos de transparencia algorítmica</strong> que permitan a los humanos comprender el razonamiento de la IA</li>
                        <li>Desarrollar <strong>métricas de confianza</strong> que guíen los procesos de recalibración</li>
                        <li>Crear <strong>marcos de gobernanza ética</strong> específicos para el sector público</li>
                    </ul>
                    
                    <h3>Limitaciones y Riesgos Identificados</h3>
                    <p><strong>Limitaciones del estudio:</strong> El análisis se limitó a un municipio sueco, lo que puede limitar la generalización a otros contextos culturales y organizacionales. Además, el período de observación fue de 18 meses, insuficiente para evaluar efectos a largo plazo.</p>
                    
                    <p><strong>Riesgos emergentes:</strong> Se identificaron tres riesgos críticos: (1) <strong>desigualdad de acceso</strong> a herramientas de IA entre diferentes niveles organizacionales, (2) <strong>opacidad en procesos algorítmicos</strong> que puede erosionar la confianza, y (3) <strong>falta de protocolos</strong> para supervisión ética en casos de conflicto entre decisiones humanas y algorítmicas.</p>
                    
                    <h3>Validación del Marco Conceptual</h3>
                    <p>El marco conceptual de colaboración simbiótica se <strong>valida parcialmente</strong> a través de los resultados obtenidos. La emergencia de competencias híbridas y la evolución hacia roles colaborativos confirman la viabilidad del modelo. Sin embargo, se requiere <strong>refinamiento en los mecanismos de gobernanza</strong> para abordar los riesgos identificados y asegurar la sostenibilidad del modelo a largo plazo.</p>
                </section>
            </div>
        </div>

        <footer class="footer">
            <p>Estudio de caso: Municipio Sueco | Metodología Gioia | Análisis Cualitativo</p>
        </footer>
    </div>
</body>
</html>
